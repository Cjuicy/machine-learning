# 1 前言

## 1.1 日常生活中的机器学习

## 1.2 关键组件

### 1.2.1 数据

### 1.2.2 模型

### 1.2.3 目标函数

目标函数：定义模型优劣程度的度量。

当任务在试图**预测数值**时，最常见的损失函数是**平方误差**（squared error）

解决**分类问题**时，最常见的目标函数是**最小化错误率**。



### 1.2.4 优化算法

基本方法：梯度下降（gradient descent）



## 1.3 各种机器学习问题

### 1.3.1 监督学习

监督学习（supervised learning）擅长在“给定输入特征”的情况下预测标签。

#### 回归

回归（regression）是最简单的监督学习任务之一。（预测房价，预测电影评分等等）

#### 分类

分类（classification）问题：我们希望模型能够预测样本属于那个类别（category，正式成为类（class））

在回归中，我们训练一个回归函数来输出一个数值；而在分类中，我们训练一个分类器，它的输出即为预测的类别。

不是所有的错误都是均等的，宁愿错误地分入一个相关的类别，也不愿错误地分入一个遥远的类别，这通常被称为层次分类（hierarchical classification）

#### 标记问题

学习预测不相互排斥的类别问题被称为多标签分类（multi-label classification）

#### 搜索

在信息检索领域，我们希望对一组项目进行排序，在海量搜索结果中找到用户最需要的那部分。

#### 推荐系统

另一类与搜索和排名相关的问题是推荐系统（recommender system），它的目标是向特定用户进行“个性化”推荐。

问题：关于如何处理审查、激励和反馈循环的许多问题，都是重要的开放性研究问题。

#### 序列学习

不同于图像分类，房价预测等这种问题，模型只会将输入作为生成输出的“原料”。

对于输入是连续的，模型可能就需要拥有“记忆”功能。（视频片段，机器翻译等）

序列学习需要摄取输入序列或预测输出序列，或两者兼而有之。

**标记和解析**：这涉及到用属性注释文本序列。（换句话说：输入和输出的数量基本上是相同的）

**自动语音识别**：与文本相比，音频帧多得多，也就是说，音频和文本之间没有1:1的对应关系。

**文本到语音**：与自动语音识别相反，输入是文本，输出是音频文件。

**机器翻译**：在语音识别中，输入和输出的出现顺序基本相同。



### 1.3.2 无监督学习

不含有“目标”的机器学习问题为**无监督学习**（unsupervised learning）

- **聚类(clustering)问题**:没有标签的情况下，对数据进行分类。
- **主成分分析(principal component analysis)问题**：找到少量的参数来准确地捕获数据的线性相关属性。
- **因果关系(causality)和概率图模型(probabilistic graphical models)问题**：我们能否描述观察到的许多数据的根本原因。
- **生成对抗性网络(generative adversarial networks)**:为我们提供一种合成数据的方法，甚至图像和音频这样复杂的非结构化数据。



### 1.3.3 与环境互动

不管是监督学习还是无监督学习，都是预先获取大量数据，然后启动模型，不再与环境交互。这里所有学习都是在算法环境断开后进行的，被称为**离线学习**（offline learning）。

我们期望人工智能不仅能做出预测，而且能够与真实环境互动。与预测不同，“与真实环境互动”实际上会影响环境。这里的人工智能是“智能代理”，而不仅是“预测模型”。

当训练和测试数据不同时，最后一个问题提出了**分布偏移(distribution shift)的问题**。



### 1.3.4 强化学习

强化学习（reinforcement learning）

深度强化学习（deep reinforcement learning）

强化学习问题中，agent在一系列的时间步骤上与环境交互：agent从环境接收一些观察（observation），并且必须选择一个动作（action），然后通过某种机制（有时称为执行器）将其传输会环境，最后agent从环境中获得奖励（reward）。此后新的一轮循环开始。

强化学习的目标是产生一个好的策略（policy）。强化学习agent选择的“动作”受策略控制，即一个从环境观察映射到行动的功能。

<img src="动手深度学习笔记.assets/image-20220708161719211.png" alt="image-20220708161719211" style="zoom:67%;" />

我们可以将任何监督学习问题转化为强化学习问题。

强化学习还可以解决许多监督学习无法解决的问题。

强化学习者必须处理学分分配（credit assignment）问题。

强化学习可能还必须处理部分可观测性问题。

在任何时间点上，强化学习agent可能知道一个好的策略，但可能有许多更好的策略从未尝试过。强化学习agent不许不断地做出选择：是应该利用当前最好的策略，还是她说新的策略空间。（放弃一些短期回报来换取知识）

当环境可被完全观察到时，我们将强化学习问题称为**马尔可夫决策过程（markov decision process）**。当状态不依赖于之前的操作时，我们称为该问题为**上下文赌博机（contextual bandit problem）**。当没有状态，只有一组最初未知回报可用动作时，这个问题就是**经典的多臂赌博机（multi-armed bandit problem）**



## 1.4 起源



## 1.5 深度学习之路



## 1.6 成功案例

## 1.7 特点

深度学习的一个**关键优势**：它不仅取代了传统学习管道末端的浅层模型，而且还取代了劳动密集型的特征工程过程。此外，通过取代大部分特定领域的预处理，深度学习消除了以前分隔计算机视觉、语音识别、自然语言处理、医学信息学和其他应用领域的许多界限。为解决各种问题提供了一套统一的工具。

深度学习社区**引以为豪**的是：他们跨越学术界和企业界共享工具，发布了许多优秀的算法库、统计模型和经过训练的开源神经网络。

## 1.8 小结

- 机器学习研究计算机系统如何利用经验（通常是数据）来提高特定任务的性能。它结合了统计学、数据挖掘和优化的思想。通常，它是被用作实现人工智能解决方案的一种手段。
- 表示学习作为机器学习的一类，其研究的重点是如何自动找到合适的数据表示方式。深度学习是通过学习多层次的转换来进行的多层次的表示学习。
- 深度学习不仅取代了传统机器学习的浅层模型，而且取代了劳动密集型的特征工程。
- 最近在深度学习方面取得的许多进展，大都是由廉价传感器和互联网规模应用所产生的大量数据，以及（通过GPU）算力的突破来触发的。
- 整个系统优化是获得高性能的关键环节。有效的深度学习框架的开源使得这一点的设计和实现变得非常容易。

## 1.9 练习

1. 你当前正在编写的代码的哪些部分可以“学习”，即通过学习和自动确定代码中所做的设计选择来改进？你的代码是否包含启发式设计选择？
2. 你遇到的哪些问题有许多解决它们的样本，但没有具体的自动化方法？这些可能是使用深度学习的主要候选者。
3. 如果把人工智能的发展看作一场新的工业革命，那么算法和数据之间的关系是什么？它类似于蒸汽机和煤吗？根本区别是什么？
4. 你还可以在哪里应用端到端的训练方法，比如 [图1.1.2](https://zh-v2.d2l.ai/chapter_introduction/index.html#fig-ml-loop) 、物理、工程和计量经济学？

**回答**

1. 绝大多数规则与启发式的都可以用来学习，例如：图片分类、垃圾分类，
2. 水下去噪，学术界会有一些数据集可以直接处理这些问题，自动化的方法我想可能是爬虫类似这样的，或者说是自动流水线上的设备指标实时上传。
3. 在2021年吴恩达提出基于数据的深度学习无疑回答了这个问题，煤是数据，模型是蒸汽机，根本的区别是就是煤和蒸汽机的关系
4. 工程我想测距可能会有end2end的操作吧



# 2 预备知识

## 2.1 数据操作

### 2.1.1 入门

### 2.1.2 运算符

### 2.1.3 广播机制

### 2.1.4 索引和切片

### 2.1.5 节省内存

使用下面两种方法，进行张量的运算，可以节省内存（内存执行原地操作）

```
X[:] =X + Y 
X += Y
```

### 2.1.6 转换为其他python对象

### 2.1.7 小结

 深度学习存储和操作数据主要接口是张量（n维数组）。它提供了各种功能，包括基本数学运算、广播、索引、切片、内存节省和转换其他Python对象。

### 2.1.8 练习

1. 运行本节中的代码。将本节中的条件语句`X == Y`更改为`X < Y`或`X > Y`，然后看看你可以得到什么样的张量。
2. 用其他形状（例如三维张量）替换广播机制中按元素操作的两个张量。结果是否与预期相同？



## 2.2 数据预处理

pandas可以与张量兼容，本章节将简要介绍使用pandas预处理原始数据，并将原始数据转换为张量格式的步骤。

### 2.2.1 读取数据集

### 2.2.2 处理缺失值

删除法：直接忽略缺失值

**插值法**：用一个代替值弥补缺失值

通过位置索引`iloc`，我们将`data`分成`inputs`和`outputs`，其中前者为`data`的前两列，而后者为`data`的最后一列。对于`inputs`中缺少的数值，我们用同一列的均值替换“NaN”项。

```python
inputs, outputs = data.iloc[:, 0:2], data.iloc[:, 2]
inputs = inputs.fillna(inputs.mean())
```

[**对于`inputs`中的类别值或离散值，我们将“NaN”视为一个类别。**]由于“巷子类型”（“Alley”）列只接受两种类型的类别值“Pave”和“NaN”，`pandas`可以自动将此列转换为两列“Alley_Pave”和“Alley_nan”。巷子类型为“Pave”的行会将“Alley_Pave”的值设置为1，“Alley_nan”的值设置为0。缺少巷子类型的行会将 “Alley_Pave” 和 “Alley_nan”分别设置为0和1。

```python
inputs = pd.get_dummies(inputs, dummy_na=True)
```

### 2.2.3 转换为张量格式

### 2.2.4 小结

-  `pandas`软件包是Python中常用的数据分析工具中，`pandas`可以与张量兼容。
- 用`pandas`处理缺失的数据时，我们可根据情况选择用插值法和删除法。

### 2.2.5 练习

1. 删除缺失值最多的列。

2. 将预处理后的数据集转换为张量格式。

```
inputs = inputs.drop(columns=inputs.isna().sum(axis=0).idxmax())
x = torch.tensor(inputs.values)
```



## 2.3 线性代数

### 2.3.1 标量

### 2.3.2 向量

大量文献认为，**列向量**向量的**默认方向**。

#### 长度、维度和形状

向量的长度通常称为向量的维度（dimension）

### 2.3.3 矩阵

矩阵是有用的数据结构：它允许我们组织具有不同模式的数据。

### 2.3.4 张量

### 2.3.5 张量算法的基本性质

### 2.3.6 降维

#### 非降维求和

如果我们想沿[**某个轴计算`A`元素的累积总和**]，比如`axis=0`（按行计算），我们可以调用`cumsum`函数。此函数不会沿任何轴降低输入张量的维度。

```python
A.cumsum(axis=0)
```

### 2.3.7 点积（Dot Product）

### 2.3.8 矩阵-向量积

### 2.3.9 矩阵-矩阵乘法

### 2.3.10 范数

线性代数中最有用的一些运算符是**范数**（norm）。非正式地说，一个向量的**范数**告诉我们一个向量有多大。这里考虑的**大小**（size）概念不涉及维度，而是分量的大小。

在线性代数中，向量的范数是将向量映射到标量的函数$f$。



你可能会注意到，范数听起来很像距离的度量。如果你还记得欧几里得距离和毕达哥拉斯定理，那么非负性的概念和三角不等式可能会给你一些启发。事实上，欧几里得距离是一个$L_2$范数：假设$n$维向量$\mathbf{x}$中的元素是$x_1,\ldots,x_n$，其[**$L_2$*范数*是向量元素平方和的平方根：**]
$$
\|\mathbf{x}\|_2 = \sqrt{\sum_{i=1}^n x_i^2}
$$
其中，在$L_2$范数中常常省略下标$2$，也就是说$\|\mathbf{x}\|$等同于$\|\mathbf{x}\|_2$。



在深度学习中，我们更经常地使用$L_2$范数的平方。你还会经常遇到[**$L_1$范数，它表示为向量元素的绝对值之和：**]
$$
\|\mathbf{x}\|_1 = \sum_{i=1}^n \left|x_i \right|
$$
与$L_2$范数相比，$L_1$范数受异常值的影响较小。为了计算$L_1$范数，我们将绝对值函数和按元素求和组合起来。




$L_2$范数和$L_1$范数都是更一般的$L_p$范数的特例：
$$
\|\mathbf{x}\|_p = \left(\sum_{i=1}^n \left|x_i \right|^p \right)^{1/p}
$$
类似于向量的$L_2$范数，[**矩阵**]$\mathbf{X} \in \mathbb{R}^{m \times n}$(**的*Frobenius范数*（Frobenius norm）是矩阵元素平方和的平方根：**)

$$
\|\mathbf{X}\|_F = \sqrt{\sum_{i=1}^m \sum_{j=1}^n x_{ij}^2}
$$


Frobenius范数满足向量范数的所有性质，它就像是矩阵形向量的$L_2$范数。
调用以下函数将计算矩阵的Frobenius范数。




#### 范数和目标

在深度学习中，我们经常试图解决优化问题：**最大化**分配给观测数据的概率;**最小化**预测和真实观测之间的距离。用向量表示物品（如单词、产品或新闻文章），以便最小化相似项目之间的距离，最大化不同项目之间的距离。**目标**，或许是深度学习算法最重要的组成部分（除了数据），通常被表达为**范数**。

### 2.3.11 关于线性代数的更多信息

### 2.3.12 小结

- 标量、向量、矩阵和张量是线性代数中的基本数学对象。
- 向量泛化自标量，矩阵泛化自向量。
- 标量、向量、矩阵和张量分别具有零、一、二和任意数量的轴。
- 一个张量可以通过`sum`和`mean`沿指定的轴降低维度。
- 两个矩阵的按元素乘法被称为他们的Hadamard积。它与矩阵乘法不同。
- 在深度学习中，我们经常使用范数，如$L_1$范数、$L_2$范数和Frobenius范数。
- 我们可以对标量、向量、矩阵和张量执行各种操作。



### 2.3.14 练习

1. 证明一个矩阵$\mathbf{A}$的转置的转置是$\mathbf{A}$，即$(\mathbf{A}^\top)^\top = \mathbf{A}$。
2. 给出两个矩阵$\mathbf{A}$和$\mathbf{B}$，证明“它们转置的和”等于“它们和的转置”，即$\mathbf{A}^\top + \mathbf{B}^\top = (\mathbf{A} + \mathbf{B})^\top$。
3. 给定任意方阵$\mathbf{A}$，$\mathbf{A} + \mathbf{A}^\top$总是对称的吗?为什么?
4. 我们在本节中定义了形状$(2,3,4)$的张量`X`。`len(X)`的输出结果是什么？
5. 对于任意形状的张量`X`,`len(X)`是否总是对应于`X`特定轴的长度?这个轴是什么?
6. 运行`A/A.sum(axis=1)`，看看会发生什么。你能分析原因吗？
7. 考虑一个具有形状$(2,3,4)$的张量，在轴0、1、2上的求和输出是什么形状?
8. 为`linalg.norm`函数提供3个或更多轴的张量，并观察其输出。对于任意形状的张量这个函数计算得到什么?

<img src="https://discuss.d2l.ai/uploads/default/original/2X/d/d4ecced3611b6686fb8ddaeb31d143ccfe488fd2.jpeg" alt="d4ecced3611b6686fb8ddaeb31d143ccfe488fd2.jpeg (1152×3332)" style="zoom:80%;" />

## 2.4 微积分

将拟合模型的任务分解为**两个关键问题**：

- **优化**（optimization）：用模型拟合观测数据的过程
- **泛化**（generalization）：数学原理和实践者的智慧，能够指导我们生成出有效性超出用于训练的数据集本身的模型。



### 2.4.1 导数和微分

%matplotlib inline就是模仿命令行来访问magic函数的在Python中独有的形式。



```python
if legend is None:
    legend = []

# set_figsize(figsize)
display.set_matplotlib_formats('svg')
d2l.plt.rcParams['figure.figsize'] = figsize # matplotlibrc动态配置

# 如果未传入axes的值则获取画布当前的axes（本例会默认创建）
axes = axes if axes else d2l.plt.gca()

# 如果 `X` 有一个轴，输出True
def has_one_axis(X):
    return (hasattr(X, "ndim") and X.ndim == 1 or # X有ndim属性且其值为1
            isinstance(X, list) and not hasattr(X[0], "__len__")) # X为列表且其首个元素没有"__len__"属性

if has_one_axis(X):
    # 如果是一个轴，将其列表化
    X = [X]

if Y is None:
    # 如果没有传入Y参数，X为包含X长度个空列表的大列表，Y为X
    X, Y = [[]] * len(X), X

elif has_one_axis(Y):
    # 如果 Y 只有一个轴，将其列表化
    Y = [Y]

if len(X) != len(Y):
    # 如果X的长度和Y的长度不一样，X改为Y长度数个X
    X = X * len(Y)

axes.cla() # 清除axes

for x, y, fmt in zip(X, Y, fmts):
    if len(x): # 如果X的元素x不为空
        axes.plot(x, y, fmt)
    else:
        axes.plot(y, fmt)
```

### 2.4.2 偏导数

### 2.4.3 梯度

### 2.4.4 链式法则

### 2.4.5 小结

- 微分和积分是微积分的两个分支，前者可以应用于深度学习中的优化问题。
- 导数可以被解释为函数相对于其变量的瞬时变化率，它也是函数曲线的切线的斜率。
- 梯度是一个向量，其分量是多变量函数相对于其所有变量的偏导数。
- 链式法则使我们能够微分复合函数。



### 2.4.6 练习

1. 绘制函数$y = f(x) = x^3 - \frac{1}{x}$和其在$x = 1$处切线的图像。
2. 求函数$f(\mathbf{x}) = 3x_1^2 + 5e^{x_2}$的梯度。
3. 函数$f(\mathbf{x}) = \|\mathbf{x}\|_2$的梯度是什么？
4. 你可以写出函数$u = f(x, y, z)$，其中$x = x(a, b)$，$y = y(a, b)$，$z = z(a, b)$的链式法则吗?

```python
#第一题
plot(x, [x**3-1/x, 4*x-4], ‘x’, ‘f(x)’, legend=[‘f(x)’, ‘Tangent line (x=1)’]
```

<img src="https://discuss.d2l.ai/uploads/default/original/2X/2/2874e9507ba661f92a0636d3fa7abe019e6ffaf3.jpeg" alt="img" style="zoom: 67%;" />



## 2.5 自动微分

深度学习框架通过自动计算导数，即**自动微分**（automatic differentiation）来加快求导。实际中，根据我们设计的模型，系统会构建一个**计算图**（computational graph），来跟踪计算是哪些数据通过哪些操作组合起来产生输出。自动微分使系统能够随后反向传播梯度。这里，**反向传播**（backpropagate）意味着跟踪整个计算图，填充关于每个参数的偏导数。



### 2.5.1 一个简单的例子

### 2.5.2 非标量变量的反向传播

### 2.5.3 分离计算

### 2.5.4 Python控制流的梯度计算

使用自动微分的一个好处是：

[**即使构建函数的计算图需要通过Python控制流（例如，条件、循环或任意函数调用），我们仍然可以计算得到的变量的梯度**]。

### 2.5.5 小结

深度学习框架可以自动计算导数：我们首先将梯度附加到想要对其计算偏导数的变量上。然后我们记录目标值的计算，执行它的反向传播函数，并访问得到的梯度。

### 2.5.6 练习

1. 为什么计算二阶导数比一阶导数的开销要更大？
2. 在运行反向传播函数之后，立即再次运行它，看看会发生什么。
3. 在控制流的例子中，我们计算`d`关于`a`的导数，如果我们将变量`a`更改为随机向量或矩阵，会发生什么？
4. 重新设计一个求控制流梯度的例子，运行并分析结果。
5. 使$f(x)=\sin(x)$，绘制$f(x)$和$\frac{df(x)}{dx}$的图像，其中后者不使用$f'(x)=\cos(x)$。

<img src="https://discuss.d2l.ai/uploads/default/original/2X/6/68eff5c8416b2a0b72d220facb6de3598571e956.jpeg" alt="img" style="zoom: 67%;" />

## 2.6 概率！

**(概率计算不够熟练，需要好好去了解一下)**

概率是一种灵活的语言，用于说明我们的确定程度，并且它可以有效地应用于广泛的领域中。

### 2.6.1 基本概率论



#### 概率论公理

**概率**（probability）可以被认为是将集合映射到真实值的函数。在给定的样本空间$\mathcal{S}$中，事件$\mathcal{A}$的概率，表示为$P(\mathcal{A})$，满足以下属性：

- 对于任意事件$\mathcal{A}$，其概率从不会是负数，即$P(\mathcal{A}) \geq 0$；
- 整个样本空间的概率为$1$，即$P(\mathcal{S}) = 1$；
- 对于**互斥**（mutually exclusive）事件（对于所有$i \neq j$都有$\mathcal{A}_i \cap \mathcal{A}_j = \emptyset$）的任意一个可数序列$\mathcal{A}_1, \mathcal{A}_2, \ldots$，序列中任意一个事件发生的概率等于它们各自发生的概率之和，即$P(\bigcup_{i=1}^{\infty} \mathcal{A}_i) = \sum_{i=1}^{\infty} P(\mathcal{A}_i)$。



#### 随机变量

### 2.6.2 处理多个随机变量

#### 联合概率

第一个被称为**联合概率**（joint probability）$P(A=a,B=b)$。给定任意值$a$和$b$，联合概率可以回答：$A=a$和$B=b$同时满足的概率是多少？ 

#### 条件概率

联合概率的不等式带给我们一个有趣的比率：$0 \leq \frac{P(A=a, B=b)}{P(A=a)} \leq 1$。我们称这个比率为**条件概率**（conditional probability），并用$P(B=b \mid A=a)$表示它：它是$B=b$的概率，前提是$A=a$已发生。

#### 贝叶斯定理

使用条件概率的定义，我们可以得出统计学中最有用的方程之一：**Bayes定理**（Bayes' theorem）。根据**乘法法则**（multiplication rule ）可得到$P(A, B) = P(B \mid A) P(A)$。根据对称性，可得到$P(A, B) = P(A \mid B) P(B)$。假设$P(B)>0$，求解其中一个条件变量，我们得到：
$$
P(A \mid B) = \frac{P(B \mid A) P(A)}{P(B)}
$$
请注意，这里我们使用紧凑的表示法：其中$P(A, B)$是一个**联合分布**（joint distribution），$P(A \mid B)$是一个**条件分布**（conditional distribution）。这种分布可以在给定值$A = a, B=b$上进行求值。

#### 边际化

为了能进行事件概率求和，我们需要**求和法则**（sum rule），即$B$的概率相当于计算$A$的所有可能选择，并将所有选择的联合概率聚合在一起：
$$
P(B) = \sum_{A} P(A, B)
$$
这也称为**边际化**（marginalization）。边际化结果的概率或分布称为**边际概率**（marginal probability）或**边际分布**（marginal distribution）。

#### 独立性

#### 应用



### 2.6.3 期望和方差



### 2.6.4 小结

- 我们可以从概率分布中采样。
- 我们可以使用联合分布、条件分布、Bayes定理、边缘化和独立性假设来分析多个随机变量。
- 期望和方差为概率分布的关键特征的概括提供了实用的度量形式。



### 2.6.5 练习

1. 进行$m=500$组实验，每组抽取$n=10$个样本。改变$m$和$n$，观察和分析实验结果。
2. 给定两个概率为$P(\mathcal{A})$和$P(\mathcal{B})$的事件，计算$P(\mathcal{A} \cup \mathcal{B})$和$P(\mathcal{A} \cap \mathcal{B})$的上限和下限。（提示：使用[友元图](https://en.wikipedia.org/wiki/Venn_diagram)来展示这些情况。)
3. 假设我们有一系列随机变量，例如$A$、$B$和$C$，其中$B$只依赖于$A$，而$C$只依赖于$B$，你能简化联合概率$P(A, B, C)$吗？（提示：这是一个[马尔可夫链](https://en.wikipedia.org/wiki/Markov_chain)。)
4. 在 :numref:`subsec_probability_hiv_app`中，第一个测试更准确。为什么不运行第一个测试两次，而是同时运行第一个和第二个测试?

**第一题**
设定 m = 5000, n = 10，得到结果如下：

<img src="https://img-blog.csdnimg.cn/20210403111402307.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzQyODkwODAw,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述" style="zoom:50%;" />

设定 m = 500, n = 100，得到结果如下：

<img src="https://img-blog.csdnimg.cn/20210403111330720.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzQyODkwODAw,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述" style="zoom:50%;" />

对比以上结果可知，第一张图效果更好，更加趋近于 0.167。原因可能是第一张图实验组数为 5000 组，而第二张图只有 500 组，虽然两者总实验次数相同，但是第一张图的实验组数要更多一些。考虑到每一组都可能存在偏差，实验组数越多，实验偏差就会分布的更加平均，效果就会更好。

**第二题**
对于$ P ( A ∪ B ) P(A \cup B)P(A∪B)$，上限是 $P(A) + P(B)$，下限是 $max\{P(A), P(B)\}$。

对于$P ( A ∩ B P(A \cap BP(A∩B)$，上限是$min\{P(A), P(B)\}$，下限是 0。

**第三题**
$P(A, B, C) = P(A) P(B|A) P(C|B)$

**第四题**
原因是如果进行两次第一种测试，两次测试没有条件独立性，不能使用上面的公式进行计算，而且两次测试结果大概率相同，效果并不好。

## 2.7 查阅资料

### 2.7.1  查找模块中的所有函数和类

### 2.7.2 查找特定函数和类的用法

### 2.7.3 小结

### 2.7.4 练习



# 3 线性神经网络

## 3.1 线性回归

**回归**（regression）是能为一个或多个自变量与因变量之间关系建模的一类方法。



### 3.1.1 线性回归的基本元素

#### 线性模型

**仿射变换（affine transformation）**的特点是通过加权和对特征进行**线性变换**（linear transformation），并通过偏置项来进行**平移**（translation）。

仿射变换由所选权重和偏置决定



在开始寻找最好的**模型参数**（model parameters）$\mathbf{w}$和$b$之前，我们还需要两个东西：

（1）一种模型质量的度量方式；

（2）一种能够更新模型以提高模型预测质量的方法。

#### 损失函数

回归问题中最常用的损失函数是平方误差函数。当样本$i$的预测值为$\hat{y}^{(i)}$，其相应的真实标签为$y^{(i)}$时，平方误差可以定义为以下公式：
$$
l^{(i)}(\mathbf{w}, b) = \frac{1}{2} \left(\hat{y}^{(i)} - y^{(i)}\right)^2
$$
为了度量模型在整个数据集上的质量，我们需计算在训练集$n$个样本上的损失均值（也等价于求和）
$$
L(\mathbf{w}, b) =\frac{1}{n}\sum_{i=1}^n l^{(i)}(\mathbf{w}, b) =\frac{1}{n} \sum_{i=1}^n \frac{1}{2}\left(\mathbf{w}^\top \mathbf{x}^{(i)} + b - y^{(i)}\right)^2
$$
在训练模型时，我们希望寻找一组参数（$\mathbf{w}^*, b^*$），这组参数能最小化在所有训练样本上的总损失。如下式：
$$
\mathbf{w}^*, b^* = \operatorname*{argmin}_{\mathbf{w}, b}\  L(\mathbf{w}, b)
$$

#### 解析解

#### 随机梯度下降

我们通常会在每次需要计算更新的时候随机抽取一小批样本，这种变体叫做**小批量随机梯度下降**（minibatch stochastic gradient descent）。



在每次迭代中，我们首先随机抽样一个小批量$\mathcal{B}$，它是由固定数量的训练样本组成的。然后，我们计算小批量的平均损失关于模型参数的导数（也可以称为梯度）。最后，我们将梯度乘以一个预先确定的正数$\eta$，并从当前参数的值中减掉。

我们用下面的数学公式来表示这一更新过程（$\partial$表示偏导数）：
$$
(\mathbf{w},b) \leftarrow (\mathbf{w},b) - \frac{\eta}{|\mathcal{B}|} \sum_{i \in \mathcal{B}} \partial_{(\mathbf{w},b)} l^{(i)}(\mathbf{w},b)
$$
总结一下，算法的步骤如下：

（1）初始化模型参数的值，如随机初始化；

（2）从数据集中随机抽取小批量样本且在负梯度的方向上更新参数，并不断迭代这一步骤。

对于平方损失和仿射变换，我们可以明确地写成如下形式:


$$
\begin{aligned} \mathbf{w} &\leftarrow \mathbf{w} -  \frac{\eta}{|\mathcal{B}|} \sum_{i \in \mathcal{B}} \partial_{\mathbf{w}} l^{(i)}(\mathbf{w}, b) = \mathbf{w} - \frac{\eta}{|\mathcal{B}|} \sum_{i \in \mathcal{B}} \mathbf{x}^{(i)} \left(\mathbf{w}^\top \mathbf{x}^{(i)} + b - y^{(i)}\right),\\ b &\leftarrow b -  \frac{\eta}{|\mathcal{B}|} \sum_{i \in \mathcal{B}} \partial_b l^{(i)}(\mathbf{w}, b)  = b - \frac{\eta}{|\mathcal{B}|} \sum_{i \in \mathcal{B}} \left(\mathbf{w}^\top \mathbf{x}^{(i)} + b - y^{(i)}\right). \end{aligned}
$$
公式中的$\mathbf{w}$和$\mathbf{x}$都是向量。在这里，更优雅的向量表示法比系数表示法（如$w_1, w_2, \ldots, w_d$）更具可读性。$|\mathcal{B}|$表示每个小批量中的样本数，这也称为**批量大小**（batch size）。$\eta$表示**学习率**（learning rate）。批量大小和学习率的值通常是手动预先指定，而不是通过模型训练得到的。这些可以调整但不在训练过程中更新的参数称为**超参数**（hyperparameter）。**调参**（hyperparameter tuning）是选择超参数的过程。超参数通常是我们根据训练迭代结果来调整的，而训练迭代结果是在独立的**验证数据集**（validation dataset）上评估得到的。



#### 用模型进行预测

给定特征估计目标的过程通常称为**预测**（prediction）或**推断**（inference）。



### 3.1.2 矢量化加速

矢量化代码通常会带来数量级的加速。另外，我们将更多的数学运算放到库中，而无须自己编写那么多的计算，从而减少了出错的可能性。



### 3.1.3 正态分布与平方损失！（最大似然是什么）

正态分布和线性回归之间的关系很密切。正态分布（normal distribution），也称为**高斯分布**（Gaussian distribution），最早由德国数学家高斯（Gauss）应用于天文学研究。简单的说，若随机变量$x$具有均值$\mu$和方差$\sigma^2$（标准差$\sigma$），其正态分布概率密度函数如下：
$$
p(x) = \frac{1}{\sqrt{2 \pi \sigma^2}} \exp\left(-\frac{1}{2 \sigma^2} (x - \mu)^2\right)
$$
改变均值会产生沿$x$轴的偏移，增加方差将会分散分布、降低其峰值。



均方误差损失函数（简称均方损失）可以用于线性回归的一个原因是：我们假设了观测中包含噪声，其中噪声服从正态分布。



### 3.1.4 从线性回归到深度网络

#### 神经网络图

#### 生物学



### 3.1.5 小结

- 机器学习模型中的关键要素是训练数据、损失函数、优化算法，还有模型本身。
- 矢量化使数学表达上更简洁，同时运行的更快。
- 最小化目标函数和执行极大似然估计等价。
- 线性回归模型也是一个简单的神经网络。

### 3.1.6 练习

1. 假设我们有一些数据$x_1, \ldots, x_n \in \mathbb{R}$。我们的目标是找到一个常数$b$，使得最小化$\sum_i (x_i - b)^2$。
    1. 找到最优值$b$的解析解。
    1. 这个问题及其解与正态分布有什么关系?
1. 推导出使用平方误差的线性回归优化问题的解析解。为了简化问题，可以忽略偏置$b$（我们可以通过向$\mathbf X$添加所有值为1的一列来做到这一点）。
    1. 用矩阵和向量表示法写出优化问题（将所有数据视为单个矩阵，将所有目标值视为单个向量）。
    1. 计算损失对$w$的梯度。
    1. 通过将梯度设为0、求解矩阵方程来找到解析解。
    1. 什么时候可能比使用随机梯度下降更好？这种方法何时会失效？
1. 假定控制附加噪声$\epsilon$的噪声模型是指数分布。也就是说，$p(\epsilon) = \frac{1}{2} \exp(-|\epsilon|)$
    1. 写出模型$-\log P(\mathbf y \mid \mathbf X)$下数据的负对数似然。
    1. 你能写出解析解吗？
    1. 提出一种随机梯度下降算法来解决这个问题。哪里可能出错？（提示：当我们不断更新参数时，在驻点附近会发生什么情况）你能解决这个问题吗？

答案地址：

[《动手学深度学习》参考答案(第二版)-第三章 - 简书 (jianshu.com)](https://www.jianshu.com/p/8b8206988655)



## 3.2 线性回归从零开始实现

### 3.2.1 生成数据集

```python
def synthetic_data(w, b, num_examples):  #@save
    """生成y=Xw+b+噪声"""
    X = torch.normal(0, 1, (num_examples, len(w)))
    y = torch.matmul(X, w) + b
    y += torch.normal(0, 0.01, y.shape)
    return X, y.reshape((-1, 1))
    
true_w = torch.tensor([2, -3.4])
true_b = 4.2
features, labels = synthetic_data(true_w, true_b, 1000)

print('features:', features[0],'\nlabel:', labels[0])

d2l.set_figsize()
d2l.plt.scatter(features[:, (1)].detach().numpy(), labels.detach().numpy(), 1)
```

### 3.2.2 读取数据集

```python
def data_iter(batch_size, features, labels):
    num_examples = len(features)
    indices = list(range(num_examples))
    # 这些样本是随机读取的，没有特定的顺序
    random.shuffle(indices)
    for i in range(0, num_examples, batch_size):
        batch_indices = torch.tensor(
            indices[i: min(i + batch_size, num_examples)])
        yield features[batch_indices], labels[batch_indices]
        

batch_size = 10
for X, y in data_iter(batch_size, features, labels):
    print(X, '\n', y)
    break
```

### 3.2.3 初始化模型参数

```python
w = torch.normal(0, 0.01, size=(2,1), requires_grad=True)
b = torch.zeros(1, requires_grad=True)
```

### 3.2.4 定义模型

```python
def linreg(X, w, b):  #@save
    """线性回归模型"""
    return torch.matmul(X, w) + b
```

### 3.2.5 定义损失函数

```python
def squared_loss(y_hat, y):  #@save
    """均方损失"""
    return (y_hat - y.reshape(y_hat.shape)) ** 2 / 2
```

### 3.2.6 定义优化算法

```python
def sgd(params, lr, batch_size):  #@save
    """小批量随机梯度下降"""
    with torch.no_grad():
        for param in params:
            param -= lr * param.grad / batch_size
            param.grad.zero_()
```

### 3.2.7 训练

概括一下，我们将执行以下循环：

* 初始化参数
* 重复以下训练，直到完成
    * 计算梯度$\mathbf{g} \leftarrow \partial_{(\mathbf{w},b)} \frac{1}{|\mathcal{B}|} \sum_{i \in \mathcal{B}} l(\mathbf{x}^{(i)}, y^{(i)}, \mathbf{w}, b)$
    * 更新参数$(\mathbf{w}, b) \leftarrow (\mathbf{w}, b) - \eta \mathbf{g}$



设置超参数

```python
lr = 0.03
num_epochs = 3
net = linreg
loss = squared_loss
```

```python
for epoch in range(num_epochs):
    for X, y in data_iter(batch_size, features, labels):
        l = loss(net(X, w, b), y)  # X和y的小批量损失
        # 因为l形状是(batch_size,1)，而不是一个标量。l中的所有元素被加到一起，
        # 并以此计算关于[w,b]的梯度
        l.sum().backward()
        sgd([w, b], lr, batch_size)  # 使用参数的梯度更新参数
    with torch.no_grad():
        train_l = loss(net(features, w, b), labels)
        print(f'epoch {epoch + 1}, loss {float(train_l.mean()):f}')
```

```python
print(f'w的估计误差: {true_w - w.reshape(true_w.shape)}')
print(f'b的估计误差: {true_b - b}')
```



### 3.2.8 小结

* 我们学习了深度网络是如何实现和优化的。在这一过程中只使用张量和自动微分，不需要定义层或复杂的优化器。
* 这一节只触及到了表面知识。在下面的部分中，我们将基于刚刚介绍的概念描述其他模型，并学习如何更简洁地实现其他模型。

### 3.2.9 练习
1. 如果我们将权重初始化为零，会发生什么。算法仍然有效吗？
1. 假设你是[乔治·西蒙·欧姆](https://en.wikipedia.org/wiki/Georg_Ohm)，试图为电压和电流的关系建立一个模型。你能使用自动微分来学习模型的参数吗?
1. 您能基于[普朗克定律](https://en.wikipedia.org/wiki/Planck%27s_law)使用光谱能量密度来确定物体的温度吗？
1. 如果你想计算二阶导数可能会遇到什么问题？你会如何解决这些问题？
1. 为什么在`squared_loss`函数中需要使用`reshape`函数？
1. 尝试使用不同的学习率，观察损失函数值下降的快慢。
1. 如果样本个数不能被批量大小整除，`data_iter`函数的行为会有什么变化？

答案地址：[《动手学深度学习》参考答案(第二版)-第三章 - 简书 (jianshu.com)](https://www.jianshu.com/p/8b8206988655)



## 3.3 线性回归简洁实现

### 3.3.1 生成数据集

```python
import numpy as np
import torch
from torch.utils import data
from d2l import torch as d2l
```

```python
true_w = torch.tensor([2, -3.4])
true_b = 4.2
features, labels = d2l.synthetic_data(true_w, true_b, 1000)
```

### 3.3.2 读取数据集

```python
def load_array(data_arrays, batch_size, is_train=True):  #@save
    """构造一个PyTorch数据迭代器"""
    dataset = data.TensorDataset(*data_arrays)
    return data.DataLoader(dataset, batch_size, shuffle=is_train)
```

```python
batch_size = 10
data_iter = load_array((features, labels), batch_size)
next(iter(data_iter))
```

### 3.3.3 定义模型

```python
# nn是神经网络的缩写
from torch import nn

net = nn.Sequential(nn.Linear(2, 1))
```

### 3.3.4 初始化模型参数

```python
net[0].weight.data.normal_(0, 0.01)
net[0].bias.data.fill_(0)
```

### 3.3.5 定义损失函数

```python
loss = nn.MSELoss()
```

### 3.3.6 定义优化算法

```python
trainer = torch.optim.SGD(net.parameters(), lr=0.03)
```

### 3.3.7 训练

回顾一下：在每个迭代周期里，我们将完整遍历一次数据集（`train_data`），不停地从中获取一个小批量的输入和相应的标签。对于每一个小批量，我们会进行以下步骤:

* 通过调用`net(X)`生成预测并计算损失`l`（前向传播）。
* 通过进行反向传播来计算梯度。
* 通过调用优化器来更新模型参数。

```python
num_epochs = 3
for epoch in range(num_epochs):
    for X, y in data_iter:
        l = loss(net(X) ,y)
        trainer.zero_grad()
        l.backward()
        trainer.step()
    l = loss(net(features), labels)
    print(f'epoch {epoch + 1}, loss {l:f}')
```

```python
w = net[0].weight.data
print('w的估计误差：', true_w - w.reshape(true_w.shape))
b = net[0].bias.data
print('b的估计误差：', true_b - b)
```

### 3.3.8 小结

* 我们可以使用PyTorch的高级API更简洁地实现模型。
* 在PyTorch中，`data`模块提供了数据处理工具，`nn`模块定义了大量的神经网络层和常见损失函数。
* 我们可以通过`_`结尾的方法将参数替换，从而初始化参数。

### 3.3.9 练习

1. 如果将小批量的总损失替换为小批量损失的平均值，你需要如何更改学习率？

1. 查看深度学习框架文档，它们提供了哪些损失函数和初始化方法？用Huber损失代替原损失，即

$$
l(y,y') = \begin{cases}|y-y'| -\frac{\sigma}{2} & \text{ if } |y-y'| > \sigma \\ \frac{1}{2 \sigma} (y-y')^2 & \text{ 其它情况}\end{cases}
$$
3. 你如何访问线性回归的梯度？

答案地址：[《动手学深度学习》参考答案(第二版)-第三章 - 简书 (jianshu.com)](https://www.jianshu.com/p/8b8206988655)





## 3.4 softmax回归

通常，机器学习实践者用*分类*这个词来描述两个有微妙差别的问题： 1. 我们只对样本的“硬性”类别感兴趣，即属于哪个类别； 2. 我们希望得到“软性”类别，即得到属于每个类别的概率。 这两者的界限往往很模糊。其中的一个原因是：即使我们只关心硬类别，我们仍然使用软类别的模型。

### 3.4.1 分类问题

统计学家很早以前就发明了一种表示分类数据的简单方法：*独热编码*（one-hot encoding）。 独热编码是一个向量，它的分量和类别一样多。 类别对应的分量设置为1，其他所有分量设置为0。

### 3.4.2 网络架构

 与线性回归一样，softmax回归也是一个单层神经网络。

![../_images/softmaxreg.svg](https://zh-v2.d2l.ai/_images/softmaxreg.svg)

### 3.4.3 全连接层的参数开销

具体来说，对于任何具有$d$个输入和$q$个输出的全连接层，参数开销为$\mathcal{O}(dq)$，这个数字在实践中可能高得令人望而却步。幸运的是，将$d$个输入转换为$q$个输出的成本可以减少到$\mathcal{O}(\frac{dq}{n})$，其中超参数$n$可以由我们灵活指定，以在实际应用中平衡参数节约和模型有效性。



### 3.4.4 softmax运算

$$
\hat{\mathbf{y}} = \mathrm{softmax}(\mathbf{o})\quad \text{其中}\quad \hat{y}_j = \frac{\exp(o_j)}{\sum_k \exp(o_k)}
$$

$$
\operatorname*{argmax}_j \hat y_j = \operatorname*{argmax}_j o_j
$$

### 3.4.5 小批量样本的矢量化

### 3.4.6 损失函数

#### 对数似然

#### softmax及其导数！

#### 交叉熵损失

### 3.4.7 信息论基础
*信息论*（information theory）涉及编码、解码、发送以及尽可能简洁地处理信息或数据。

#### 熵！
信息论的核心思想是量化数据中的信息内容。在信息论中，该数值被称为分布$P$的*熵*（entropy）。可以通过以下方程得到：

$$
H[P] = \sum_j - P(j) \log P(j)
$$
信息论的基本定理之一指出，为了对从分布$p$中随机抽取的数据进行编码，我们至少需要$H[P]$“纳特（nat）”对其进行编码。“纳特”相当于*比特*（bit），但是对数底为$e$而不是2。因此，一个纳特是$\frac{1}{\log(2)} \approx 1.44$比特。

#### 信息量

#### 重新审视交叉熵

如果把熵$H(P)$想象为“知道真实概率的人所经历的惊异程度”，那么什么是交叉熵？交叉熵*从*$P$*到*$Q$，记为$H(P, Q)$。你可以把交叉熵想象为“主观概率为$Q$的观察者在看到根据概率$P$生成的数据时的预期惊异”。当$P=Q$时，交叉熵达到最低。在这种情况下，从$P$到$Q$的交叉熵是$H(P, P)= H(P)$。

简而言之，我们可以从两方面来考虑交叉熵分类目标：（i）最大化观测数据的似然；（ii）最小化传达标签所需的惊异。



### 3.4.8 模型预测和评估

在接下来的实验中，我们将使用**精度**（accuracy）来评估模型的性能。精度等于正确预测数与预测总数之间的比率。

### 3.4.9 小结

* softmax运算获取一个向量并将其映射为概率。
* softmax回归适用于分类问题，它使用了softmax运算中输出类别的概率分布。
* 交叉熵是一个衡量两个概率分布之间差异的很好的度量，它测量给定模型编码数据所需的比特数。



### 3.4.10 练习
1. 我们可以更深入地探讨指数族与softmax之间的联系。
    1. 计算softmax交叉熵损失$l(\mathbf{y},\hat{\mathbf{y}})$的二阶导数。
    1. 计算$\mathrm{softmax}(\mathbf{o})$给出的分布方差，并与上面计算的二阶导数匹配。
1. 假设我们有三个类发生的概率相等，即概率向量是$(\frac{1}{3}, \frac{1}{3}, \frac{1}{3})$。
    1. 如果我们尝试为它设计二进制代码，有什么问题？
    1. 你能设计一个更好的代码吗？提示：如果我们尝试编码两个独立的观察结果会发生什么？如果我们联合编码$n$个观测值怎么办？
1. softmax是对上面介绍的映射的误称（虽然深度学习领域中很多人都使用这个名字）。真正的softmax被定义为$\mathrm{RealSoftMax}(a, b) = \log (\exp(a) + \exp(b))$。
    1. 证明$\mathrm{RealSoftMax}(a, b) > \mathrm{max}(a, b)$。
    1. 证明$\lambda^{-1} \mathrm{RealSoftMax}(\lambda a, \lambda b) > \mathrm{max}(a, b)$成立，前提是$\lambda > 0$。
    1. 证明对于$\lambda \to \infty$，有$\lambda^{-1} \mathrm{RealSoftMax}(\lambda a, \lambda b) \to \mathrm{max}(a, b)$。
    1. soft-min会是什么样子？
    1. 将其扩展到两个以上的数字。

答案地址：[《动手学深度学习》参考答案(第二版)-第三章 - 简书 (jianshu.com)](https://www.jianshu.com/p/8b8206988655)



## 3.5 图像分类数据集

```python
%matplotlib inline
import torch
import torchvision
from torch.utils import data
from torchvision import transforms
from d2l import torch as d2l

d2l.use_svg_display()
```



### 3.5.1 读取数据集

```python
# 通过ToTensor实例将图像数据从PIL类型变换成32位浮点数格式，
# 并除以255使得所有像素的数值均在0到1之间
trans = transforms.ToTensor()
mnist_train = torchvision.datasets.FashionMNIST(
    root="../data", train=True, transform=trans, download=True)
mnist_test = torchvision.datasets.FashionMNIST(
    root="../data", train=False, transform=trans, download=True)
```

```python
len(mnist_train), len(mnist_test)
mnist_train[0][0].shape
```

```python
def get_fashion_mnist_labels(labels):  #@save
    """返回Fashion-MNIST数据集的文本标签"""
    text_labels = ['t-shirt', 'trouser', 'pullover', 'dress', 'coat',
                   'sandal', 'shirt', 'sneaker', 'bag', 'ankle boot']
    return [text_labels[int(i)] for i in labels]
```

可视化这些样本

```python
def show_images(imgs, num_rows, num_cols, titles=None, scale=1.5):  #@save
    """绘制图像列表"""
    figsize = (num_cols * scale, num_rows * scale)
    _, axes = d2l.plt.subplots(num_rows, num_cols, figsize=figsize)
    axes = axes.flatten()
    for i, (ax, img) in enumerate(zip(axes, imgs)):
        if torch.is_tensor(img):
            # 图片张量
            ax.imshow(img.numpy())
        else:
            # PIL图片
            ax.imshow(img)
        ax.axes.get_xaxis().set_visible(False)
        ax.axes.get_yaxis().set_visible(False)
        if titles:
            ax.set_title(titles[i])
    return axes
```

```python
X, y = next(iter(data.DataLoader(mnist_train, batch_size=18)))
show_images(X.reshape(18, 28, 28), 2, 9, titles=get_fashion_mnist_labels(y));
```

### 3.5.2 读取小批量

```python
batch_size = 256

def get_dataloader_workers():  #@save
    """使用4个进程来读取数据"""
    return 4

train_iter = data.DataLoader(mnist_train, batch_size, shuffle=True,
                             num_workers=get_dataloader_workers())
```

查看读取训练数据所需要的时间

```pyhton
timer = d2l.Timer()
for X, y in train_iter:
    continue
f'{timer.stop():.2f} sec'
```

### 3.5.3 整合所有组件

```python
def load_data_fashion_mnist(batch_size, resize=None):  #@save
    """下载Fashion-MNIST数据集，然后将其加载到内存中"""
    trans = [transforms.ToTensor()]
    if resize:
        trans.insert(0, transforms.Resize(resize))
    trans = transforms.Compose(trans)
    mnist_train = torchvision.datasets.FashionMNIST(
        root="../data", train=True, transform=trans, download=True)
    mnist_test = torchvision.datasets.FashionMNIST(
        root="../data", train=False, transform=trans, download=True)
    return (data.DataLoader(mnist_train, batch_size, shuffle=True,
                            num_workers=get_dataloader_workers()),
            data.DataLoader(mnist_test, batch_size, shuffle=False,
                            num_workers=get_dataloader_workers()))
```

通过指定`resize`参数来测试`load_data_fashion_mnist`函数的图像大小调整功能。

```python
train_iter, test_iter = load_data_fashion_mnist(32, resize=64)
for X, y in train_iter:
    print(X.shape, X.dtype, y.shape, y.dtype)
    break
```

### 3.5.4 小结

* Fashion-MNIST是一个服装分类数据集，由10个类别的图像组成。我们将在后续章节中使用此数据集来评估各种分类算法。
* 我们将高度$h$像素，宽度$w$像素图像的形状记为$h \times w$或（$h$,$w$）。
* 数据迭代器是获得更高性能的关键组件。依靠实现良好的数据迭代器，利用高性能计算来避免减慢训练过程。

### 3.5.5 练习


1. 减少`batch_size`（如减少到1）是否会影响读取性能？
1. 数据迭代器的性能非常重要。你认为当前的实现足够快吗？探索各种选择来改进它。
1. 查阅框架的在线API文档。还有哪些其他数据集可用？

答案地址：[《动手学深度学习》参考答案(第二版)-第三章 - 简书 (jianshu.com)](https://www.jianshu.com/p/8b8206988655)



## 3.6 softmax回归的从零开始实现

```python
import torch
from torch import nn
from d2l import torch as d2l

batch_size = 256
train_iter, test_iter = d2l.load_data_fashion_mnist(batch_size)
```

### 3.6.1 初始化模型参数

```python
num_inputs = 784
num_outputs = 10

W = torch.normal(0, 0.01, size=(num_inputs, num_outputs), requires_grad=True)
b = torch.zeros(num_outputs, requires_grad=True)
```

### 3.6.2 定义softmax函数

回想一下，[**实现softmax**]由三个步骤组成：

1. 对每个项求幂（使用`exp`）；
1. 对每一行求和（小批量中每个样本是一行），得到每个样本的规范化常数；
1. 将每一行除以其规范化常数，确保结果的和为1。

### 3.6.3 定义模型

### 3.6.4 定义损失函数

### 3.6.5 分类精度

### 3.6.6 训练

### 3.6.7 预测

### 3.6.8 小结
* 借助softmax回归，我们可以训练多分类的模型。
* 训练softmax回归循环模型与训练线性回归模型非常相似：先读取数据，再定义模型和损失函数，然后使用优化算法训练模型。大多数常见的深度学习模型都有类似的训练过程。
### 3.6.9 练习

1. 在本节中，我们直接实现了基于数学定义softmax运算的`softmax`函数。这可能会导致什么问题？提示：尝试计算$\exp(50)$的大小。
1. 本节中的函数`cross_entropy`是根据交叉熵损失函数的定义实现的。它可能有什么问题？提示：考虑对数的定义域。
1. 你可以想到什么解决方案来解决上述两个问题？
1. 返回概率最大的分类标签总是最优解吗？例如，医疗诊断场景下你会这样做吗？
1. 假设我们使用softmax回归来预测下一个单词，可选取的单词数目过多可能会带来哪些问题?

答案地址：[《动手学深度学习》参考答案(第二版)-第三章 - 简书 (jianshu.com)](https://www.jianshu.com/p/8b8206988655)



## 3.7 softmax回归的简洁实现

### 3.7.1 初始化模型参数

```python
# PyTorch不会隐式地调整输入的形状。因此，
# 我们在线性层前定义了展平层（flatten），来调整网络输入的形状
net = nn.Sequential(nn.Flatten(), nn.Linear(784, 10))

def init_weights(m):
    if type(m) == nn.Linear:
        nn.init.normal_(m.weight, std=0.01)

net.apply(init_weights)
```

### 3.7.2 重新审视Softmax实现

```pyhton
loss = nn.CrossEntropyLoss(reduction='none')
```

### 3.7.3 优化算法

```python
trainer = torch.optim.SGD(net.parameters(), lr=0.1)
```

### 3.7.4 训练

```python
num_epochs = 10
d2l.train_ch3(net, train_iter, test_iter, loss, num_epochs, trainer)
```



### 3.7.5 小结

* 使用深度学习框架的高级API，我们可以更简洁地实现softmax回归。
* 从计算的角度来看，实现softmax回归比较复杂。在许多情况下，深度学习框架在这些著名的技巧之外采取了额外的预防措施，来确保数值的稳定性。这使我们避免了在实践中从零开始编写模型时可能遇到的陷阱。


### 3.7.6 练习

1. 尝试调整超参数，例如批量大小、迭代周期数和学习率，并查看结果。
1. 增加迭代周期的数量。为什么测试精度会在一段时间后降低？我们怎么解决这个问题？

答案地址：[《动手学深度学习》参考答案(第二版)-第三章 - 简书 (jianshu.com)](https://www.jianshu.com/p/8b8206988655)



# 4 多层感知机

## 4.1 多层感知机

### 4.1.1 隐藏层



