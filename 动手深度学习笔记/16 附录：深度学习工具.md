# 16 附录：深度学习工具

## 16.1 使用 Jupyter Notebooks

### 16.1.1 在本地编辑和运行代码

### 16.1.2 高级选项

#### Jupyter中的Markdown文件

#### 在远程服务器上运行 Jupyter Notebook

### 16.1.3 小结

* 使用Jupyter Notebook工具，我们可以编辑、运行和为本书做贡献。
* 使用端口转发在远程服务器上运行Jupyter Notebook。

### 16.1.4 练习

1. 在本地计算机上使用Jupyter Notebook编辑并运行本书中的代码。
1. 使用Jupyter Notebook通过端口转发来远程编辑和运行本书中的代码。
1. 对于两个方矩阵，测量$\mathbf{A}^\top \mathbf{B}$与$\mathbf{A} \mathbf{B}$在$\mathbb{R}^{1024 \times 1024}$中的运行时间。哪一个更快？



## 16.2 使用Amazon SageMaker

### 16.2.1 注册

### 16.2.2 创建SageMaker实例

### 16.2.3 运行和停止实例

### 16.2.4 更新Notebook

### 16.2.5 小结

* 我们可以使用Amazon SageMaker创建一个GPU的notebook实例来运行本书的密集型代码。
* 我们可以通过Amazon SageMaker实例上的终端更新notebooks。

### 16.2.6 练习

1. 使用Amazon SageMaker编辑并运行任何需要GPU的部分。
1. 打开终端以访问保存本书所有notebooks的本地目录。




## 16.3 使用Amazon EC2实例

### 16.3.1 创建和运行EC2实例

#### 预置位置

#### 增加限制

#### 启动实例

#### 连接到实例

### 16.3.2 安装CUDA

### 16.3.3 安装库以运行代码

### 16.3.4 远程运行Jupyter笔记本

### 16.3.5 关闭未使用的实例

### 16.3.6 小结

* 我们可以按需启动和停止实例，而不必购买和制造我们自己的计算机。
* 在使用支持GPU的深度学习框架之前，我们需要安装CUDA。
* 我们可以使用端口转发在远程服务器上运行Jupyter笔记本。

### 16.3.7 练习

1. 云提供了便利，但价格并不便宜。了解如何启动[spot实例](https://aws.amazon.com/ec2/spot/)以降低成本。
1. 尝试使用不同的GPU服务器。它们有多快？
1. 尝试使用多GPU服务器。你能把事情扩大到什么程度？






## 16.4 选择服务器和GPU

### 16.4.1 选择服务器

### 16.4.2 选择GPU

### 16.4.3 小结

* 在构建服务器时，请注意电源、PCIe总线通道、CPU单线程速度和散热。
* 如果可能，你应该购买最新一代的GPU。
* 使用云进行大型部署。
* 高密度服务器可能不与所有GPU兼容。在你购买之前，请检查一下机械和散热规格。
* 为提高效率，请使用FP16或更低的精度。


## 16.5 为本书做贡献

### 16.5.1 提交微小更改

### 16.5.2 大量文本或代码修改

### 16.5.3 提交主要更改

#### 安装Git

#### 登录GitHub

#### 克隆存储库

#### 编辑和推送

#### 提交Pull请求

### 16.5.4 小结

* 你可以使用GitHub为本书做贡献。
* 你可以直接在GitHub上编辑文件以进行微小更改。
* 要进行重大更改，请分叉存储库，在本地编辑内容，并在准备好后再做出贡献。
* 尽量不要提交巨大的Pull请求，因为这会使它们难以理解和合并。最好拆分为几个小一点的。

### 16.5.5 练习

1. 启动并分叉`d2l-ai/d2l-en`存储库。
1. 如果发现任何需要改进的地方（例如，缺少引用），请提交Pull请求。
1. 通常更好的做法是使用新分支创建Pull请求。学习如何用[Git分支](https://git-scm.com/book/en/v2/Git-Branching-Branches-in-a-Nutshell)来做这件事。


## 16.6 d2l API 文档

### 16.6.1 模型

### 16.6.2 数据

### 16.6.3 训练

### 16.6.4 公用

