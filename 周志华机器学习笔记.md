# 第2章 模型评估与选择

## 2.1 经验误差与过拟合

**训练误差（training error）/或经验误差（empirical error）**

学习器在训练集上的误差



**泛化误差（generalization error）**

在新样本上的误差



**过拟合（overfitting）**

学习器学的太好，把训练样本自身的一些特点当做了所有潜在样本都会具有的一般性质，导致泛化性能下降



**欠拟合（underfitting）**

指对训练样本的一般性质尚未学好



**模型选择（model selection）**

当使用不同的参数配置，也会产生不同的模型，我们应该选择哪一个学习算法、使用哪一种参数配置？这就是机器学习中的“模型选择”问题。



## 2.2 评估方法

**测试集（testing set）**

用于测试学习器对新样本的判别能力。



**测试误差（testing error）**

作为泛化误差的近似



既要训练又要测试，有什么方法呢？



### 2.2.1 留出法

**留出法（hold-out）**

直接将数据集D划分为两个互斥的集合，其中一个集合作为训练集S,另一个作为测试集T。在S上训练出模型后，用T来评估其测试误差，作为对泛化误差的估计。



**注意：**

训练/测试集的划分要尽可能保持数据分布一致性，避免因数据划分过程引入额外的偏差而对最终结果产生影响。



**从采样（sampling）的角度来看待数据集的划分过程**

保留类别比例的采样方式通常称为“分层采样”（stratified sampling）

不同的划分将导致不同的训练/测试集



**保真性（fidelity）**



**常见做法**

将大约2/3~4/5的样本用于训练，剩余的样本用于测试



### 2.2.2 交叉验证法

交叉验证法（cross validation）先将数据集D划分为k个大小相似的互斥子集，每个子集D_i都尽可能保持数据分布的一致性，即从D中通过分层采样得到。然后，每次用k-1个子集的并集作为训练集，余下的那个子集作为测试集；这样就可获得k组训练/测试集，从而可进行k次训练和测试，最终返回的是这个k个测试结果的均值。

通常把交叉验证法称为“k折交叉验证”（k-fold cross validation）

k最常用的取值是10，此时称为10折交叉验证

k折交叉验证通常要随机使用不同的划分重复p次



**留一法（Leave-One-Out——LOO）**

交叉验证的特例，与初始数据集相比只少了一个样本。留一法的评估结往往被认为比较准确。

**缺陷：**

在数据集较大时，训练m个模型的计算开销可能是难以忍受的。



### 2.2.3 自助法

**自助法（bootstrapping）**

减少训练样本规模不同造成的影响，同时还能比较高效地进行实验估计

直接以自助采样法（bootstrap sampling）为基础，给定包含m个样本的数据集D，我们对它进行采样产生数据集D’，每次随机从D总挑选一个样本的数据集D‘，然后再将该样本放回初始数据集D中，使得该样本在下次采样时仍有可能被采到，这个过程重复执行m次后，我们就得到了包含m个样本的数据集D’，这就是自助采样的结果。



**包外估计（out-of-bag estimate）**



**优点：**

自助法在数据集较小，难以有效划分训练/训练测试集时很有用处。

**缺点：**

自助法产生的数据集改变了初始数据集的分布，这会引入估计偏差



### 2.2.4 调参与最终模型

大多数学习算法都有写参数（parameter）需要设定，参数配置不同，学习模型的性能往往有显著的差别。除了要对使用学习算法进行选择，还需要对算法那参数进行设定，这就是通常所说的“参数调节”或简称“调参”（parameter tuning）。



**另外注意：**
我们通常把学得模型在实际使用中遇到的数据称为测试数据，为了加以区分，模型评估与选择中用于评估测试的数据集常称为“验证集”（validation set）



## 2.3 性能度量

**性能度量（performance measure）**

衡量模型泛化能力的评价标准



**均方误差（mean squared error）**

回归任务最常用的性能度量

<img src="周志华机器学习笔记.assets/image-20211116105448301.png" alt="image-20211116105448301" style="zoom: 80%;" />

更一般的，对数据分布D个概率密度函数p(·)，均方误差的描述

<img src="周志华机器学习笔记.assets/image-20211116105604621.png" alt="image-20211116105604621" style="zoom: 80%;" />



### 2.3.1 错误率与精度

**错误率**

分类错误的样本数占样本总数的比例

<img src="周志华机器学习笔记.assets/image-20211116105826664.png" alt="image-20211116105826664" style="zoom:80%;" />

更一般的，对数据分布D个概率密度函数p(·)，的错误率

<img src="周志华机器学习笔记.assets/image-20211116105944762.png" alt="image-20211116105944762" style="zoom:80%;" />







**精度**

分类正确的样本数占样本总数的比例

<img src="周志华机器学习笔记.assets/image-20211116105841104.png" alt="image-20211116105841104" style="zoom:80%;" />

更一般的，对数据分布D个概率密度函数p(·)，的精度

<img src="周志华机器学习笔记.assets/image-20211116105957227.png" alt="image-20211116105957227" style="zoom:80%;" />





### 2.3.2查准率、查全率与F1

查准率（precision）与查全率（recall）用于满足更加细致的需求，也是一种性能度量



**TP**：真正例（true positive）

**FP**：假正例（false positive）

**TN**：真反例（true negative）

**FN**：假反例（false negative）

TP+FP+TN+FN = 样例总数

| 真实情况 | 预测结果     | 预测结果     |
| -------- | ------------ | ------------ |
| 真实情况 | 正例         | 反例         |
| 正例     | TP（真正例） | FN（假反例） |
| 反例     | FP（假正例） | TN（真反例） |



查准率P和查全率R分别定义为

<img src="周志华机器学习笔记.assets/image-20211116111249346.png" alt="image-20211116111249346" style="zoom:80%;" />

查准率和查全率是一对矛盾的度量



**P-R图**可以直观地显示出学习器在样本总体上的查全率、查准率

若一个学习器的P-R曲线被另一个学习器的曲线完全“**包住**”，则可断言后者的性能优于前者

如果发生了交叉，但是我们还是想要比较高下，这时一个比较合理的判断是比较P-R曲线下**面积的大小**



**平衡点（Break-Even Point——BEP）**

它是查**准率 = 查全率**时的取值



**F1度量（是BEP的优化）**

基于查准率与查全率的调和平均（harmonic mean）

<img src="周志华机器学习笔记.assets/image-20211116112106098.png" alt="image-20211116112106098" style="zoom:80%;" />



**F_β（F1度量的一般形式）**

用于对查准率与查全率不同的需求

能够让我们表达出队查准率/查全率的不同偏好

<img src="周志华机器学习笔记.assets/image-20211116112456541.png" alt="image-20211116112456541" style="zoom:80%;" />



**再多个混淆矩阵上综合考察查准率和查全率**

先计算查准率和查全率，然后再计算平均值

宏查准率（macro-P）

宏查全率（macro-R）

宏F1（macro-F1）

<img src="周志华机器学习笔记.assets/image-20211116112803352.png" alt="image-20211116112803352" style="zoom:80%;" />



**先对混淆矩阵（误差矩阵）进行平均，得到TP、FP、TN、FN的平均值，在计算出查准率，查全率**

微查准率（micro-P）

微查全率（micro-R）

微F1（micro-F1）

<img src="周志华机器学习笔记.assets/image-20211116113143980.png" alt="image-20211116113143980" style="zoom:80%;" />

<img src="周志华机器学习笔记.assets/image-20211116113201462.png" alt="image-20211116113201462" style="zoom:80%;" />



### 2.3.3 ROC与AUC

很多学习器是为测试样本产生一个实值或概率预测，然后将这个预测值与一个分类阈值（threshold）进行比较，若大于阈值则分为正类，否则为反类。

重视“查准率”，选择排序中靠前的位置进行截断

重视“查全率”，选择排序中靠后的位置进行截断

为了综合考虑学习器在不同任务下的“泛化性能”的好坏，或者说“一般情况下”泛化性能的好坏。ROC曲线则思从这个角度出发来研究学习器泛化性能的有力工具

**ROC——受试者工作特征（Receiver Operation Characterristic）曲线**

与P-R曲线使用查准率。查全率为纵、横轴不同，ROC曲线的纵轴是**“真正例率**”（True Positive Rate,简称TPR），横轴是“**假正例率**”（False Positive Rate，简称FPR）

<img src="周志华机器学习笔记.assets/image-20211117103949689.png" alt="image-20211117103949689" style="zoom:80%;" />

**AUC（Area under ROC Curve）**

若一个学习器的ROC曲线被另一个学习器的曲线完全“包住”，则可断言后者的性能优于前者。若两个学习器的ROC曲线发生交叉，那么合理的判据是比较ROC曲线下的面积，即AUC（Area under ROC Curve）

<img src="周志华机器学习笔记.assets/image-20211117104259250.png" alt="image-20211117104259250" style="zoom:80%;" />



结合图表，这就是一个梯形公式

下图是另一种计算公式，给定m+个正例，m-个反例，令D+和D-分别表示正、反例集合，则排序“Loss”损失定义为

<img src="周志华机器学习笔记.assets/image-20211117104340936.png" alt="image-20211117104340936" style="zoom:80%;" />

即考虑每一对正、反例，若正例的预测值小于反例，则记一个“罚分”，若相等，则记0.5个“罚分”、容易看出l_rank对应的是ROC曲线之上的面积。

<img src="周志华机器学习笔记.assets/image-20211117104647112.png" alt="image-20211117104647112" style="zoom:80%;" />

为了帮助理解提供两个视频连接：

**master学堂**

https://www.bilibili.com/video/BV1H54y1D7or?share_source=copy_web

**小萌五分钟**

https://www.bilibili.com/video/BV1wz4y197LU?share_source=copy_web





### 2.3.4 代价敏感错误率与代价曲线

为了权衡不同类型错误所造成的不同损失，可为错误赋予**“非均等代价”（unequal cost）**

我们根据任务的领域知识设定一个**“代价矩阵”（cost matrix）**

其中cost_ij 表示将第i类样本预测为第j类样本的代价。

损失程度相差越大，cost01与cost02值的差别越大

<img src="周志华机器学习笔记.assets/image-20211117143942728.png" alt="image-20211117143942728" style="zoom:80%;" />

在非均等代价下，我们所希望的不再是简单地最小化错误次数，而是希望最小化**“总体代价”（total cost）**

将上图第0类作为正类，第1类作为反类，D+与D-分别代表样例集D的正例子集，和反例子集，则**“代价敏感”（cost-sensitive）**错误率为

<img src="周志华机器学习笔记.assets/image-20211117144311888.png" alt="image-20211117144311888" style="zoom:80%;" />

若令cost_ij中的i，j取值不限于0、1则可以定义出多分类任务的代价敏感性能度量



ROC曲线不能直接反映出学习器的期望总体代价，而**“代价曲线”（cost curve）**则可达到该目的。代价曲线图的横轴是取值为[0,1]的正例概率代价

<img src="周志华机器学习笔记.assets/image-20211117144615243.png" alt="image-20211117144615243" style="zoom:80%;" />

其中p是样例为正例的概率；纵轴是取值为[0,1]的归一化代价

<img src="周志华机器学习笔记.assets/image-20211117144718516.png" alt="image-20211117144718516" style="zoom:80%;" />

（“规范化”normalization 是将不同变化范围的值映射到相同的固定范围中，常见的是[0,1]，此时亦称“归一化”）

FPR是式子定义的假正例率，FNR=1-TPR是假反例率

<img src="周志华机器学习笔记.assets/image-20211117151455293.png" alt="image-20211117151455293" style="zoom:67%;" />

## 2.4 比较检验

机器学习的性能比较，要比上面的更加复杂。

1. 我们希望比较的是泛化性能，然而通过实验评估方法我们获得的是测试集上的性能，两者的对比结果可能未必相同。
2. 测试集上的性能与测试集本身的选择有很大的关系，且不论使用不同大小的测试集会得到不同的结果，即便使用相同大小的测试集，若包含的测试样例不同，测试结果也会不同。
3. 很多机器学习算法本身有一定的随机性，即便用相同的参数设置在同一个测试集上多次运行，其结果也会有所不同。



统计假设检验（hypothesis test）为我们进行学习器性能比较提供了重要依据。



本节默认以错误率为性能度量，用ε表示



### 2.4.1 假设检验

 (看不懂)

二项检验（binomial test）

置信度（confidence）

t检验（t-test）

双边（two-tailed）



### 2.4.2 交叉验证t检验

使用了5x2交叉验证，能大概看懂

成对t检验（paired t-tests）



### 2.4.3 McNemar检验

列联表（contingency table）



### 2.4.4 Friendman检验与Nemeny后续检验





## 2.5 偏差与方差

“偏差—方差分解”（bias-variance decompose）是解释学习算法泛化性能的一种重要工具

偏差—方差分解，试图对学习算法的期望泛化错误率进行拆解

泛化误差可分解为偏差、方差、与噪声之和

期望输出与真实标记的差别称为偏差（bias）

偏差、方差、噪声的含义：

- 偏差：度量了学习算法的期望预测与真实结果的偏离程度，即刻画了学习算法本身的拟合能力
- 方差：度量了同样大小的训练集的变动所导致的学习性能的变化，即刻画了数据扰动所造成的影响
- 噪声：表达了在当前任务上任何学习算法所能达到的期望泛化误差的下界，即刻画了学习问题本身的难度

偏差—方差分解说明，泛化性能是由学习算法的能力、数据的充分性以及学习任务本身的难度所共同决定的。



**偏差—方差窘境（bias-variance dilemma）**

偏差与方差是有冲突的，这称为偏差—方差窘境（bias-variance dilemma）



## 2.6 阅读材料

机器学习过程设计许多类型的代价，除了误分类代价，还有测试代价、标记代价、属性代价等，即便仅考虑误分类代价，仍可进一步划分为基于类别的误分类代价以及基于样本的误分类代价。



**代价敏感学习（cost-sensitive learning）**

专门研究非均等代价下的学习



# 第3章 线性模型

## 3.1 基本形式

线性模型（linear model）试图学得一个通过属性的线性组合来进行预测的函数。





## 3.2 线性回归

线性回归（linear regression）

线性回归试图学得一个线性模型以尽可能准确地预测实值输出标记。



均方误差有非常好的集合意义，它对应了常用的欧几里得距离或简称“欧氏距离”（Euclidean distance）。

基于均方误差最小化来进行模型求解的方法称为“最小二乘法”（learning square method）

在线性回归中，最小二乘法就是试图找到一条直线，使所有样本到直线上的欧氏距离之和最小



多元线性回归（multivariate linear  regression）



对数线性回归（log-linear regression）



广义线性模型（generalized linear model）

联系函数（link function）



## 3.3 对数几率回归

若要做分类任务怎么办？

只需要找一个单调可微单调函数将分类任务的真实标记y与线性回归模型的预测值联系起来



“替代函数”（surrogate function）

“对数几率函数”（logistic function）



“对数几率回归”（logistic regression 亦称 logit regression）



“极大似然法”（maximum likelihood method）

"对数似然"（log-likelihood）



## 3.4 线性判别分析

**线性判别分析（Linear Discriminant Analysis 简称LDA）**

线性判别分析是一种经典的线性学习方法，在二分类问题上应为最早由Fisher提出，亦称“Fisher 判别分析”

**LDA思想**

给定训练样例集，设法将样例投影到一条直线上，使得同类样例的投影点尽可能接近、异类样例的投影点尽可能远离；在对新样本进行分类时，将其投影到同样的这条直线上，再根据投影点的位置来确定新样本的类别。



类内散度矩阵（within-class scatter matrix）



类间散度矩阵（between-class scatter matrix）



广义瑞利商（generalized Rayleigh quotient）



## 3.5 多分类学习

在更多的情形下，我们基于一些基本策略，利用二分类学习器来解决多分类问题



**多分类学习的基本思想**

“拆解法”，即将多分类任务拆为若干个二分类任务求解。

具体来说：先对问题进行拆分，然后为拆出的每个二分类任务训练一个分类器，在测试时，对这些分类器的预测结果进行集成以获得最终的多分类结果。



**最经典的拆分策略有三种**

- 一对一（One vs. One 简称OvO）
- 一对其余（One vs. Rest 简称OvR）
- 多对多（Many vs. Many 简称MvM）



**MvM技术：“纠错输出码”（Error Correcting Output Codes，简称ECOC）**

ECOC是将编码的思想引入类别拆分，并尽可能在解码过程中具有容错性。



类别划分通过“编码矩阵”（coding matrix）指定。

编码矩阵有多种形式，常见的主要有二元码和三元码

- 二元码
  - 将每个类别分别指定为正类和反类
- 三元码
  - 在正反类之外，还可以指定“停用类”



**为什么称为“纠错输出码”呢？**

这是因为在测试阶段，ECOC编码对分类器的错误有一定的容忍和修正。



## 3.6 类别不平衡问题

前面介绍的分类学习方法都有一个共同的基本假设，即不同类别的训练样例数目相当。如果不同类别的训练样例数目稍微有差别，通常影响不大，但若差别很大，则会对学习过程造成困扰。



**类别不平衡（class-imbalance）**

类别不平衡就是指分类任务中不同类别的训练样例数目差别很大的情况。



**再缩放（rescaling）——（亦称“再平衡”—rebalance）**



**再缩放技术大体上有三类做法**

- 对训练集里的反类样例进行“欠采样”（undersampling）
  - 即去除一些反例使得正、反例数目接近，然后再进行学习
- 对训练集里的正类样例进行“过采样”（oversampling）
  - 即增加一些正例使得正、反例数目接近，然后再进行学习
- 阈值移动（threshold-moving）
  - 直接基于原始训练集进行学习，但在用训练好的分类器进行与测试，将式子嵌入到其决策过程中



**值的一提**

"再缩放"也是”代价铭感学习“（cost-sensitive learning）的基础。



## 3.7 阅读材料

“稀疏表示”（sparse representation）

“稀疏性”（sparsity）

代价敏感学习中研究得最多的是基于类别的“误分类代价”（misclassificatin cost）

“多标记学习”（multi-label learning ）这是机器学习中近年来相当活跃的一个研究领域





# 第4章 决策树

## 4.1 基本流程

**决策树（decision tree）**

是一类常见的机器学习方法

决策树是基于树结构来进行决策的，这恰是人类在面临决策问题时一种很自然的处理方式。



**一般的一棵决策树包含一个根结点、若干个内部结点和若干个叶结点**

- 叶结点对应于决策结果，其他每结点则对应于一个属性测试
- 每个结点包含的样本集合根据属性测试的结果被划分到子结点中
- 根结点包含样本全集，从根结点到每个叶结点的路径对应了一个判定测试序列。
- 决策树学习的目的是为了产生一棵泛化能力强，即处理未见示例能力强的决策树，其基本流程遵循简单且直观的“分而治之”（divide-and-conquer）策略



在决策树基本算法中，有三种情形会导致递归返回：

1. 当前结点包含的样本全属于同一类别，无需划分
2. 当前属性集为空，或是所有样本在所有属性上取值相同，无法划分
3. 当前结点包含的样本集合为空，不能划分



## 4.2 划分选择

决策树学习的关键是如何选择最优划分属性

随着划分过程不断进行，我们希望决策树的分支结点所包含的样本尽可能属于同一类别，即结点“纯度”（purity）越来越高。



### 4.2.1 信息增加

“信息熵“（information entropy）是度量样本集合纯度最常用的一种指标



”信息增加“（information gain）



一般而言，信息增益越大，则意味着使用属性a来进行划分所得的“纯度提升”越大，因此，我们可用信息增益来进行决策树的划分属性选择。



### 4.2.2 增益率

实际上，信息增益准则对可取值数目较多的属性有所偏好，为减少这种偏好可能带来的不利影响，著名的C4.5决策树算法不直接使用信息增量，而是使用“增益率”（gain ratio）来选择最优划分属性。



需要注意的是，增益率准则对可取值数目较少的属性有所偏好，因此C4.5算法并不是直接选择增益率最大的候选划分属性，而是使用了一个启发式：先从候选划分书信中找出新消息增益高于平均水平的属性，再从中选择增益率最高的。



### 4.2.3 基尼指数

CART决策树使用“基尼指数”（Gini index）来选择划分属性



直观来说，Gini(D)反应了从数据集D中随机抽取两个样本，其类别标记不一致的概率。因此，Gini(D)越小，则数据集D的纯度越高。



## 4.3 剪枝处理

剪枝（pruning）是决策树学习算法对付“过拟合”的主要手段



**决策树剪枝的基本策略有“预剪枝”（prepruning）和“后剪枝”（postpruning）**

- 预剪枝
  - 在决策树生成过程中，对每个结点在划分前先进行估计，若当前结点的划分不能带来决策树泛化性能提升，则停止划分并将当前结点标记为叶结点。
- 后剪枝
  - 先从训练集生成一棵完整的决策树，然后自底向上地对非叶结点进行考察，若将该结点对应的子树替换为叶结点能带来决策树泛化性能提升，则将该子树替换维叶结点。



### 4.3.1 预剪枝

预剪枝要对划分前后的泛化性能进行估计



预剪枝使得决策树的很多分支都没有“展开”，这不仅降低了过拟合的风险，还显著减少了决策树的训练时间开销和测试时间开销。但另一方面，有些分支的当前划分虽不能提升泛化性能、甚至可能导致泛化性能暂时下降，但在其基础上进行的后续划分却有可能导致性能显著提高。

预剪枝基于“贪心”本质禁止这些分支展开，给预剪枝决策树带来了欠拟合的风险。



### 4.3.2 后剪枝

后剪枝决策树通常比预剪枝决策树保留了更多的分支。一般情况下，后剪枝决策树的欠拟合风险很小，泛化性能往往优于预剪枝决策树。但后剪枝过程是在生成完全决策树之后进行的，并且要自底向上地对树种的所有非叶结点进行逐一考察，因此其徐那脸时间开销比未剪枝决策树和预剪枝决策树都要大得多。



## 4.4 连续与缺失值

讨论如何在决策树学习中使用连续属性



连续属性离散化技术派上了用场。最简单的策略是采用二分法（bi-partition）对连续属性进行处理。



需要注意的是，与离散属性不同，若当前结点划分属性为连续属性，该属性还可作为其后代结点的划分属性。



### 4.4.2 缺失值处理

现实任务重常会遇到不完整样本，即样本的某些属性值缺失。如果简单地放弃不完整的样本，仅使用过无缺失值的样本来进行学习，显然是对数据信息极大的浪费。



**我们需要解决两个问题**

1. 如何在属性值缺失的情况下进行划分属性选择？
2. 给定划分属性，若样本在该属性上的值缺失，如何对样本进行划分？



## 4.5 多变量决策树

“多变量决策树”（multivariate decision tree）就是能实现这样的“斜划分”甚至更复杂划分的决策树。



与传统的“单变量决策树”（univariate decision tree）不同，在多变量决策树的学习过程中，不是为每个非叶结点寻找一个最优划分属性，而是试图建立一个合适的线性分类器。



## 4.6 阅读材料

有一些决策树学习算法可进行“增量学习”（incremental learning），即在接收到新样本后可对已学得的模型进行调整，而不用完全重新学习。主要机制是通过调整分支路径上的划分属性次序来对数进行部分重构，代表性算法有ID4、ID5R、ITI等。

增量学习可有效地降低每次接收到新样本后的训练时间开销，但多步增量学习后的模型会与基于全部数据训练而得的模型有较大差别。





# 第5章 神经网络

## 5.1 神经元模型

神经网络（Neural networks）方面的研究很早就已出现，今天“神经网络”已是一个相当大的、多学科交叉的学科领域。

目前使用得最广泛的一种，即“神经网络是由具有适应性的简单单元组成的广泛并进行互联网的网络，它的组织能够模拟生物神经系统对真实世界物体所作出的交互反应”



神经元（neuron）

阈值（threshold）



**激活函数**

我们实际常用Sigmoid函数作为激活函数。典型的Sigmoid函数，它把可能在较大范围内变化的输入值挤压到（0,1）输出值范围内，因此有时也称为“挤压函数”（squashing function）



我们把许多个这样的神经元按一定的层次结构连接起来，就得到了神经网络。



## 5.2 感知机与多层网络

感知机（Perception）由两层神经元组成，输入层接受外接输入信号后传递给输出层，输出层是M-P神经元，亦称“阈值逻辑单元”（threshold logic unit）



需要注意的是，感知机只有输出神经元进行激活函数处理，即只拥有一层功能神经元（functional neuron），其学习能力非常有限。



要解决非线性可分问题，需考虑使用多层功能神经元。

输出层与输入层之间的一层神经元，被称为隐层或隐含层（hidden layer）隐含层和输出层神经元都是拥有激活函数的功能神经元。



更一般的，常见的神经网络是形如图5.6所示的层级结构，每层神经元与下一层神经元全互联，神经元之间不存在同层连接，也不存在跨层连接，这样的神经网络结构通常称为“多层前馈神经网络”。



神经网络的学习过程，就是根据训练数据来调整神经元之间的“连接权”（connection weight）以及每个功能神经元的阈值。换言之，神经网络“学”到的东西，蕴涵在连接权与阈值中。



## 5.3 误差逆传播算法

多层网络的学习能力比单层感知机强得多。误差逆传播算法（error BackPropagation 简称BP）是其中最杰出的代表，它是迄今最成功的神经网络学习算法。



**BP算法执行以下操作**

- 先将输入示例提供给输入神经元
- 然后逐层将信号前传，直到产生输出层的记过
- 然后计算输出层的误差，再将误差逆向传播至隐层神经元
- 最后根据隐层神经元的误差来对连接权和阈值进行调整
- 该迭代过程循环进行，直到达到某些停止条件位置



需要注意的是，BP算法的目标是要最小化训练集D上的累积误差



Hornik et al. 证明，只需要一个包含足够多神经元的隐层，多层前馈网络就能以任意精度逼近任意复杂度的连续函数。

然而，如何设置隐层神经元的个数仍是个未决问题，实际应用中通常靠“试错法”（trial-by-error）调整。



BP神经网络经常遭遇过拟合，其训练误差持续降低，但测试误差却可能上升。

**有两种策略常用来缓解BP网络的过拟合**

- 第一种策略——“早停”（early stopping）
  - 将数据分成训练集和验证集，训练集用来计算梯度、更新连接权和阈值，验证集用来估计误差，若训练集误差降低但验证集误差升高，则停止训练，同时返回最具有最小验证集误差的连接权和阈值。
- 第二种策略——“正则化”（regularization）
  - 基本思想是在误差目标函数中增加一个用于描述网络复杂度的部分，例如连接权与阈值的平方和。



## 5.4 全局最小与局部极小

神经网络的训练过程可看做一个参数寻优过程



基于梯度的搜索是使用最为广泛的参数寻优方法



**在现实任务中，人们常采用以下策略来试图“跳出”局部极小，从而进一步接近全局最小。**

- 以多组不同参数值初始化多个神经网络，按标准方法训练后，取其中误差最小的解作为最终参数。这相当于从多个不同的初始点开始搜索，这样就可能陷入不同的局部极小，从中进行选择有可能获得更接近全局最小的结果。
- 使用“模拟退火”技术，模拟退火在每一步都以一定的概率接受比当前解更差的结果，从而有助于“跳出”局部极小。在每步迭代过程中，接受“次优解”的概率要随着时间的推移而逐渐降低，从而保证算法稳定。
- 使用随机梯度下降。与标准梯度下降法精确计算梯度不同，随机梯度下降法在计算梯度时加入了随机因素。于是，即便陷入局部极小点，它计算出的梯度仍可能不为零，这样就有机会跳出局部极小，继续搜索。

此外，遗传算法（genetic algorithms）也常用来训练神经网络以更好地逼近全局最小。

**需要注意：**上述用于跳出局部极小的技术大多是启发式，理论上尚缺乏保障。



## 5.5 其他常见神经网络

只对特别常见的几种网络稍作简介。



### 5.5.1 RBF网络

RBF（Radial Basis Function，径向基函数）网络，是一种单隐层前馈神经挽留过，它使用径向基函数作为隐层神经元激活函数，而输出层则是对隐层神经元输出的线性组合。



### 5.5.2 ART网络

竞争型学习（competitive learning）是神经挽留过中最常用的无监督学习策略，在使用该策略时，网络的输出神经元相互竞争，每一时刻仅有一个竞争获胜的神经元被激活其他神经元的状态被抑制。这种机制亦称“胜者通吃”（winner-take-all）原则。

ART（Adaptive Resonance Theory，自适应协振理论）网络是竞争型学习的重要代表。



ART比较好地缓解了竞争型学习中的“可塑性-稳定性窘境”（stability-plasticity dilemma），可塑性是指神经网络有要学习新知识的能力、而稳定性则是指神经网络在学习新知识时要保持对旧知识的记忆。这就使得ART网络具有一个很重要的优点：可进行增量学习（incremental learning ）或在线学习（online learning）



### 5.5.3 SOM网络

SOM（Self-Organizing Map，自组织映射）网络是一种竞争学习型的无监督神经网络，它能将高维输入数据映射到低维空间（通常为二维），同时保持输入数据在高维空间的拓扑结构，即将高位空间中相似的样本点映射到网络输出层中的邻近神经元。



### 5.5.4 级联相关网络

一般的神经网络模型通常假定网络结构是事先固定的，训练的目的是利用训练样本来确定合适的连接权、阈值等参数。与此不同，结构自适应网络则将网络结构也当做学习的目标之一，并希望能在训练过程中找到最符合数据特点的网络结构。

级联相关（Cascade-Correlation）网络是结构自适应网络的重要代表。



与一般的前馈神经网络相比，级联相关网络无需设置网络层数、隐层神经元数目，且训练速度较快，但其在数据较小时易陷入过拟合。



### 5.5.5 Elman网络

与前馈神经挽留过不同，“递归神经网络”（recurrent neural networks）允许网络中出现环形结构，从而可让一些神经元的输出反馈回来作为输入信号。

这样的结构与信息反馈过程，使得网络在t时刻的输出状态不仅与t时刻的输入有关，还与t-1时刻的网络状态有关，从而能处理与时间有关的动态变化。



### 5.5.6 Boltzmann机

神经网络中有一类模型是为网络状态定义一个“能量”（energy），能量最小化时挽留过达到理想状态，而网络的训练就是在最小化这个能量函数。

Boltzmann机就是一种“基于能量的模型”



## 5.6 深度学习

随着云极端。大数据时代的到来，计算能力的答复提高可缓解训练低效性，训练数据的大幅增加则可降低过拟合风险，因此，以“深度学习”（deep learning）为代表的复杂模型开始受到人们的关注。



典型的深度学习模型就是很深层的神经网络。



无监督逐层训练（unsupervised layer-wise training）是多层隐层网络训练的有效手段，其基本思想是每次训练一层隐结点，训练时将上一层隐结点的输出作为输入，而本层隐结点的输出作为下一层隐结点的输入，这称为“预训练”（pre-training）；在预训练全部完成后，再对整个网络进行“微调”训练。



通过多层处理，逐渐将初始的“低层”特征表示转化为“高层”特征表示后，用“简单模型”即可完成复杂的分类等学习任务。由此可将深度学习理解为进行“特征学习”（feature learning）或“表示学习”（representation learning）



特征学习通过机器学习技术自身来产生好特征，这使机器学习向“全自动数据分析”又前进了一步。



## 5.7 阅读材料

M-P神经元模型使用最为广泛，但还有一些神经元模型也受到关注，如考虑了点位脉冲发放时间而不仅是累积电位的脉冲神经元（spiking neuron）模型



神经网络是一种难解释的“黑箱模型”，但已有一些工作尝试改善神经挽留过的可解释性，主要途径是通过神经网络中抽取易理解的符号规则。



# 第6章 支持向量机

## 6.1 间隔与支持向量

分类学习最基本的想法就是基于训练集D在样本空间中找到一个划分超平面，将不同类别的样本分开。



## 6.2 对偶问题

“对偶问题”（dual problem）



## 6.3 核函数

在本章前面的讨论中，我们假设训练样本是线性可分的，即存在一个划分超平面能将训练样本正确分类。然而在现实任务中，原始样本空间内也许并不存在一个能正确划分两类样本的超平面。



我们希望样本在特征空间内线性可分，因此特征空间的好坏对支持向量机的性能至关重要。

需要注意的是：在不知道特征映射的形式时，我并不知道什么样的核函数是合适的，而核函数也仅是隐式地定义了这个特征空间。于是，“核函数选择”成为支持向量机的最大变数。若核函数选择不合适，则意味着将样本映射到了一个不适合的特征空间，很可能导致性能不佳。



## 6.4 软间隔与正则化

在前面讨论中，我们已知假定训练样本在样本空间或特征空间中是线性可分的，及存在一个超平面能将不同类的样本完全划分开。然而在现实任务中往往很难确定合适的核函数使得训练样本在特征空间中线性可分，退一步说，即便恰好找到了某个核函数使训练集在特征空间中线性可分，也很难断定这个貌似线性可分的结果不是由于过拟合所造成的。

缓解该问题的一个办法是允许支持向量机在一些样本上出错，为此，要引入“软间隔”（soft margin）的概念

具体来说，前面介绍的支持向量机形式是要求所有样本均满足约束，即所有样本都必须划分正确，这称为“硬间隔”（hard margin），而软间隔则是允许某些样本不满足约束。



### 6.5 支持向量回归

考虑回归问题



## 6.6 核方法

支持向量机的求解通常是借助于凸优化技术，如何提高效率，使SVM能适用于大规模数据一直是研究重点。

核函数直接决定了支持向量机与核方法的最终性能，但遗憾的是，核函数的选择是一个未决问题。多核学习（multiple kernel learning）使用多个核函数并通过学习获得其最优凸组合作为最终的核函数，这实际上实在借助集成学习机制。





# 第7章 贝叶斯分类器

## 7.1 贝叶斯决策论

贝叶斯决策论（Bayesian decisiontheory）是概率框架下实施决策的基本方法。对分类任务来说，在所有相关概率都已知的理想情形下，贝叶斯决策论考虑如何基于这些概率和误判损失来选择最优的类别标记。



## 7.2 极大似然估计

估计类条件概率的一种常用策略是：

先假定其具有某种确定的概率分布形式，再基于训练样本对概率分布的参数进行估计。



事实上，概率模型的训练过程就是参数估计（parameter estimation）过程

对于参数估计，统计学界的两个学派分别提供了不同的解决方案：

- 频率主义学派（Frequentist）认为：
  - 参数虽然未知，但却是客观存在的固定值，因此，可以通过优化似然函数等准则来确定参数值
- 贝叶斯学派（Bayesian）认为：
  - 参数是未观察到的随机变量，其本身也可有分布，因此，可假定参数服从一个先验分布，然后基于观测到的数据来计算参数的后验分布。



## 7.3 朴素贝叶斯分类器

不难发现，基于贝叶斯公式（7.8）来估计后验概率P(c|**x**)的主要困难在于：类条件概率P(x|c)是所有属性上的联合概率，难以从有限的训练样本直接估计而得。为避开这个障碍，朴素贝叶斯分类器（naive Bayes classifier）采用了“属性条件独立性假设”（attribute conditional independence assumption）：对已知类别，假设所有属性相互独立，换言之，假设每个属性独立地对分类结果发生影响。



## 7.4 半朴素贝叶斯分类器

为了降低贝叶斯公式（7.8）汇总估计后验概率P(c|**x**)的困难，朴素贝叶斯分类器采用了属性条件独立性假设，但在现实任务中，这个假设往往很难成立。于是人们尝试对属性条件独立性假设进行一定程度的放松，由此产生了一类称为“半朴素贝叶斯分类器”（semi-maive Bayes classifiers）的学习方法

“独依赖估计”（One-Dependent Estimator 简称ODE）是版半朴素贝叶斯分类器最常用的一种策略。



## 7.5 贝叶斯网

贝叶斯网（Bayesian network）亦称“信念网”（belief network），它借助有向无环图（Directed Acyclic Graph，简称DAG）来刻画属性之间的依赖关系，并使用条件概率表（Conditional Probability Table，简称CPT）来描述属性的联合概率分布。



### 7.5.1 结构

贝叶斯网结构有效地表达了属性间的条件独立性



### 7.5.2 学习

若网络结构已知，即属性间的依赖关系已知，则贝叶斯网的学习过程相对简单，只需通过对训练样本“技术”，估计出每个结点的条件概率即可。但在现实应用中，我们往往并不知道网络结构，于是，贝叶斯网学习的首要任务就是更具训练数据集来找出结构最“恰当”的贝叶斯网。



### 7.5.3 推断

贝叶斯网训练好之后就能用来回答“查询”（query），即通过一些属性变化的观测值来推测其他属性变量的取值。



## 7.6 EM算法

在前面的讨论中，我们一直假设训练样本所有属性变量的值都已被观测到，即训练样本是“完整”的。但在现实应用中，往往会遇到“不完整”的训练样本，在这种存在“未观测”变量的情形下，是否仍能对模型参数进行估计呢？



EM（Expectation-Maximization）算法是常用的估计参数隐变量的利器，它是一种迭代式的方法，其基本想法是：若参数θ已知，则可以根据训练数据推断出最优隐变量**Z**的值（E步）；反之，若**Z**的值已知，则可方便地对参数θ座极大似然估计（M步）



简要来说，EM算法使用两个步骤交替计算：

第一步是期望步（E）步，利用当前估计的参数值来计算对数似然的期望值；

第二步四最大化（M）步，寻找能使E步产生的似然期望最大化的参数值，

然后，新得到的参数值重新被用于E步，......直至收敛到局部最优解。



事实上，隐变量估计问题也可通过梯度下降等优化算法求解，但由于求和项数将随着隐变量的数目以指数级上升，会给梯度计算带来麻烦，而EM算法则可看做一种非梯度优化方法。



## 7.7 阅读材料

贝叶斯网为不确定学习和推断提供了基本框架，因其强大的表示能力、良好的可解释性而广受关注。





# 第8章 集成学习

## 8.1 个体与集成

集成学习（ensemble learning）通过构建并结合多个学习器来完成学习任务，有时也被称为多分类器系统（multi-classifier system)、基于委员会的学习（committee-based learning）等。



**集成学习的一般结构：**先产生一组“个体学习器”（individual learner），再用某种策略将它们结合起来。



- 同质（homogeneous）
  - 集成中只包含同种类型的个体学习器，这样的集成是“同质”的
  - 同质集成中的个体学习器亦称“基学习器”（base learner），相应的学习算法称为“基学习算法”。
- 异质（heterogenous）
  - 异质集成中的个体学习器由不同的学习算法生成，这时就不再有基学习算法，相应的，个体学习器一般不称为基学习器，常称为“组件学习器”（component learner）或直接称为个体学习器



集成学习通过将多个学习器进行结合，常可获得比单一学习器显著优越的泛化性能。这对“弱学习器”（weak learner）尤为明显，因此集成学习的很多理论研究都是针对若学习器进行的，而基学习器有时也被直接称为弱学习器。

**需要注意的是：**虽然从理论上来说使用弱学习器集成足以获得好的性能，但在实践中处于种种考虑，例如希望使用较少的个体学习器，或是重用关于常见学习器的一些经验等，人们往往会使用比较强的学习器。



在一般经验中，如果把好坏不等的东西掺到一起，那么通常结果会是比最坏的要好一些，比最好的要坏一些。集成学习把多个学习器结合起来，如何能获得比最好的单一学习器更好的性能呢？

要获得好的集成，个体学习器应“好而不同”，即个体学习器要有一定的“准确性”，即学习器不能太坏，并且要有“多样性”（diversity），即学习器间具有差异。

然而我们必须注意到，上面的分析有一个关键假设：基学习器的误差相互独立。在现实任务中，个体学习器是为解决同一个问题训练出来的，它们显然不可能相互独立！

事实上，个体学习器的“准确性”和“多样性”本身就存在冲突。一般的，准确性很高之后，要增加多样性就需牺牲准确性。

事实上，如何产生并结合“好而不同”的个体学习器，恰是集成学习研究的核心。



根据个体学习器的生成方式，目前的集成学习方法大致可分为两大类，即个体学习器间存在强依赖关系、必须串行生成的序列化方法，以及个体学习器间不存在强依赖关系、可同时生成的并行化方法；前者的代表室Boosting，后者的代表是Bagging和“随机森林”（Random Forest）



## 8.2 Boosting

Boosting 是一族可将弱学习器提升为强学习器的算法。

这族算法的工作机制类似：先从初始训练集训练出一个基学习器，再根据基学习器的表现对训练样本分布进行调整，使得先前基学习器做错的训练样本在后续受到更多关注，然后基于调整后的样本分布来训练下一个基学习器，如此重复进行，直至基学习器数目达到实现指定的值T，最终将这个T个基学习器进行加权结合。



Boosting 组算法最著名的代表是AdaBoost

AdaBoost算法有多种推导方式，比较容易理解的是基于“加性模型”，即基学习器的线性组合来最小化指数损失函数（exponential loss function）



Boosting算法要求基学习器能对特定的数据分布进行学习，这可通过“重赋权法”（re-weighting）实施。即在训练的过程的每一轮中，根据样本分布为每个训练样本重新赋予一个权重。对无法接受带权样本的基学习算法，则可通过“重采样法”（re-sampling）来处理，即在每一轮学习中，根据样本分布对训练集重新采样，在用重采样而得的样本集对基学习器进行训练。



从偏差-方差分解的角度看，Boosting主要关注降低偏差，因此Boosting能基于泛化性能相当弱的学习器构建出很强的集成。



## 8.3 Bagging与随机森林

由8.1节可知，欲得到泛化性能强的集成，集成中的个体学习器应尽可能相互独立；虽然“独立”在现实任务中无法做到，但可以设法使基学习器尽可能具有较大的差异。

**问题：**

为了获得好的集成，我们同时还希望个体学习器不能太差。如果采样出的每个子集都完全不同，则每个基学习器只用到了一小部分训练数据，甚至不足以进行有效学习，这显然无法确保产生出比较好的基学习器。

为解决这个问题，我们可考虑使用相互有交叠的采样子集。



### 8.3.1 Bagging

Bagging是并行式集成学习方法最著名的代表。它直接基于我们在2.2.3节介绍过得自助采样法（bootstrap sampling）



值的一提的是：自主采样过程还给Bagging带来了另一个优点：由于每个基学习器只使用了初始训练集中越63.2%的样本，剩下36.8%的样本可用作验证集来对泛化性能进行“包外估计”（out-of-bag estimate）



包外样本的其他用途：

- 当基学习器是决策树时，可使用包外样本来辅助剪枝
- 用于估计决策树中各节点的后验概率以辅助对零训练样本结点的处理
- 当基学习器是神经网络时，可使用包外样本来辅助早期停止以减小过拟合风险



从偏差-方差分解的角度看，Bagging主要关注降低方差，因此它在不剪枝决策树、神经网络等易受样本扰动的学习器上效用更为明显。



### 8.3.2 随机森林

随机森林（Random Forest，简称RF）是Bagging的一个扩展变体。RF在以决策树为基学习器构建Bagging集成的基础上，进一步在决策树的训练过程中引入了随机属性来选择。

**具体来说：**传统决策树在选择划分属性时是在当前结点的属性集合（假定有d个属性）中选择一个最优属性；而在RF中，对基决策树的每个结点，先从该结点的属性集合中随机选择一个包含k个属性的子集，然后再从这个子集中选择一个最优属性用于划分。



随机森林简单、容易实现、计算开销小，令人惊奇的是，它在很多现实任务中展现出强大的性能，被誉为“代表集成学习技术水平的方法”。



随机森林的收敛性与Bagging相似。



## 8.4 结合策略

学习器结合可能会从三个方面带来好处：

- 首先，从统计的方面来看，由于学习任务的假设空间往往很大，可能有多个假设在训练集上达到同等性能，此时若使用单学习器可能因误选而导致泛化性能不佳，结合多个学习器则会减小这一风险。
- 第二，从计算的方面来看，学习算法往往会陷入局部极小，有的局部极小点所对应的泛化性能可能很糟糕，而通过多次运行之后进行结合，可降低陷入糟糕局部极小点的风险。
- 从表示的方面来看，某些学习任务的真实假设可能不在当前学习算法所考虑的假设空间中，此时若使用单学习器则肯定无效，而通过结合多个学习器，由于相应的假设空间有所扩大，有可能学得更好的近似。



### 8.4.1 平均法

对数值型输出h_i(**x**) ∈**R** ,最常见的结合策略是使用平均法（averaging）

- 简单平均法（simple averaging）
- 加权平均法（weighted averaging）

加权平均法可认为是集成学习研究的基本出发点，对给定的基学习器，不同的集成学习方法可视为通过不同的方式来确定加权平均法中的基学习器权重。



一般而言，在个体学习器性能相差较大时宜使用加权平均法，而在个体学习器性能相近时宜使用简单平均法。



### 8.4.2 投票法

- 绝对多数投票法（majority voting）

  即若某标记得票过半数，则预测为该标记；否则拒绝预测

- 相对多数投票法（plurality voting）

  即预测为得票最多的标记，若同时有多个标记获得最高票，则从中随机选取一个

- 加权投票法（weighted voting）

标准的绝对多数投票法（8.24）提供了“拒绝预测”选项，这在可靠性要求较高的学习任务中是一个很好的机制。但若学习任务要求必须提供预测结果，则绝对多数投票法将退化为相对多数投票法。因此，在不允许拒绝预测的任务中，绝对多数、相对对数投票法统称为“多数投票法”



### 8.4.3 学习法

当训练数据很多时，一种更为强大的结合策略是使用“学习法”，即通过另一个学习器来进行结合。是学习法的典型代表。

这里我们把个体学习器称为**初级学习器**，用于结合的学习器称为**次级学习器**或元学习器（meta-learner）



Stacking 先从初始数据集训练出初级学习器，然后“生成”一个新数据集用于训练次级学习器。在这个新数据集中，初级学习器的输出被当做样例输入特征，而初始样本的标记仍被当做样例标记。



## 8.5 多样性

### 8.5.1 误差-分歧分解

8.1节提到，与构建泛化能力强的集成，个体学习器应“好而不同”。现在我们来做一个简单的理论分析。



### 8.5.2 多样性度量

顾名思义，多样性度量（diversity measure）是用于度量集成中个体分类器的多样性，即估算个体学习器的多样化程度。典型做法是考虑个体分类器的两两相似/不相似性。



### 8.5.3 多样性增强

在集成学习中需要有效地生成多样性大的个体学习器。与简单地直接用初始数据训练出个体学习器相比，如何增强多样性呢？

**一般思路**：在学习过程中引入随机性，常见做法主要是对数据样本，输入属性、输出表示、算法参数进行扰动。

- 数据样本扰动

  给定初始数据集，可从中产生出不同的数据子集，再利用不同的数据子集训练出不同的个体学习器。数据样本扰动通常是基于采样法。

- 输入属性扰动

  训练样本通常由一组属性描述，不同的“子空间”（subspace，即属性子集）提供了观察数据的不同视角。显然，从不同子空间训练出的个体学习器必然有所不同。著名的随机子空间（random subspace）算法就依赖于输入属性扰动。

- 输出表示扰动

  此类做法的基本思路是对输出表示进行操纵以增强多样性。

- 算法参数扰动

  基学习算法一般都有参数需进行设置，例如神经网络的隐层神经元数、初始连接权值等，通过随机设置不同的参数，往往可生产差别较大的个体学习器。



不同的多样性增强机制可同时使用。



## 8.6 阅读材料

在集成产生之后在试图通过取出一些个体学习器来获得较小的集成，称为集成修建（ensemble pruning）这有助于减小模型的存储开销和预测时间开销。

由于集成包含多个学习器，即便个体学习汽油较好的可解释性，集成仍是黑箱模型。已有一些工作试图改善集成的可解释性。
